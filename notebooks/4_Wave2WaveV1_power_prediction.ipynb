{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from deepseries.models import Wave2WaveV1\n",
    "from deepseries.dataset import Property, TimeSeries, Seq2SeqDataLoader\n",
    "from deepseries.nn.loss import MSELoss, RMSELoss\n",
    "from deepseries.train import Learner\n",
    "from deepseries.optim import ReduceCosineAnnealingLR\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import matplotlib as mpl\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import chinese_calendar as calendar\n",
    "import datetime as dt\n",
    "info = pd.read_excel(\"../data/info.xlsx\")\n",
    "recored = info.set_index(\"contributor_id\")['huangzf']\n",
    "info = pd.read_excel(\"../data/info.xlsx\").set_index(\"contributor_id\")[['pjt_name', 'pjt_type']]\n",
    "norm_score = pd.read_csv(r\"../data/20200315_20200415.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = pd.read_csv('../data/df.csv', parse_dates=['data_time'])[['data_time', 'cid', 'value']]\n",
    "power = power.set_index(\"data_time\").groupby(\"cid\").resample(\"1H\").sum().reset_index()\n",
    "power = power.pivot(index='cid', columns='data_time', values='value')\n",
    "power = power.apply(np.log1p).iloc[:, 10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_zero = power.values == 0\n",
    "is_nan = power.isnull().values\n",
    "is_valid = ~is_zero & ~is_nan\n",
    "\n",
    "xy = np.ma.masked_array(power.values, mask=~is_valid)\n",
    "\n",
    "series_mu = xy.mean(axis=1).data.reshape(-1, 1)\n",
    "series_std = xy.std(axis=1).data.reshape(-1, 1)\n",
    "xy = (xy - series_mu) / series_std\n",
    "xy = xy.filled(0.)\n",
    "\n",
    "xy = np.expand_dims(xy, 1).astype('float32')\n",
    "\n",
    "N_TEST = 24 * 30\n",
    "N_VALID = 24 * 2\n",
    "DROP_ZERO = True\n",
    "DEC_LEN = 24 * 2\n",
    "ENC_LEN = 24 * 7\n",
    "time_free_space = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_lag(series, n):\n",
    "    lag = np.zeros_like(series)\n",
    "    lag[:, :, n:] = series[:, :, :-n]\n",
    "    return lag\n",
    "\n",
    "x_lag7 = n_lag(xy, 7 * 24)\n",
    "x_lag14 = n_lag(xy, 14 * 24)\n",
    "\n",
    "x_is_valid = np.expand_dims(is_valid, 1)\n",
    "\n",
    "x_num_features = np.concatenate([x_lag7, x_lag14, x_is_valid], axis=1).astype(\"float32\")\n",
    "\n",
    "weights = x_is_valid.astype(\"float32\") + 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_feature(x, T):\n",
    "    psin = np.sin(x * np.pi * 2 / T)\n",
    "    pcos = np.cos(x * np.pi * 2 / T)\n",
    "    return np.stack([psin, pcos], axis=0)\n",
    "\n",
    "\n",
    "xy_weekday = np.repeat(\n",
    "    np.expand_dims(\n",
    "        periodic_feature(power.columns.weekday.values, 7), axis=0), xy.shape[0], axis=0)\n",
    "\n",
    "xy_hour = np.repeat(\n",
    "    np.expand_dims(\n",
    "        periodic_feature(power.columns.hour.values, 24), axis=0), xy.shape[0], axis=0)\n",
    "\n",
    "xy_month = np.repeat(\n",
    "    np.expand_dims(\n",
    "        periodic_feature(power.columns.month.values, 12), axis=0), xy.shape[0], axis=0)\n",
    "\n",
    "def get_holiday_features(dts):\n",
    "    holidays = pd.get_dummies(pd.Series(dts).apply(lambda x: calendar.get_holiday_detail(x)[1]))\n",
    "    holidays['sick'] = np.where((power.columns >= \"2020-02-01\") & (power.columns < \"2020-03-01\"), 1, 0)\n",
    "    return holidays\n",
    "\n",
    "holidays = get_holiday_features(power.columns)\n",
    "holidays = np.expand_dims(holidays.values.transpose(1, 0), 0)\n",
    "holidays = np.repeat(holidays, xy.shape[0], axis=0)\n",
    "\n",
    "xy_num_features = np.concatenate([\n",
    "    xy_weekday,\n",
    "    xy_hour,\n",
    "    xy_month,\n",
    "    holidays\n",
    "], axis=1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_cat_features = np.expand_dims(np.arange(62), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardSpliter:\n",
    "    \n",
    "    def split(self, time_idx, enc_len, dec_len, valid_size):\n",
    "        if valid_size < 1:\n",
    "            valid_size = int(np.floor(len(time_idx) * valid_size))\n",
    "        valid_idx = time_idx[-(valid_size+enc_len):]\n",
    "        train_idx = time_idx[:-valid_size]\n",
    "        return train_idx, valid_idx\n",
    "    \n",
    "spliter = ForwardSpliter()\n",
    "train_idx, valid_idx = spliter.split(np.arange(xy.shape[2]), ENC_LEN, DEC_LEN, N_TEST+N_VALID)\n",
    "valid_idx, test_idx = spliter.split(valid_idx, ENC_LEN, DEC_LEN, N_TEST)\n",
    "\n",
    "train_xy = TimeSeries(xy[:, :, train_idx])\n",
    "valid_xy = TimeSeries(xy[:, :, valid_idx])\n",
    "\n",
    "train_xy_features = TimeSeries(xy_num_features[:, :, train_idx])\n",
    "valid_xy_features = TimeSeries(xy_num_features[:, :, valid_idx])\n",
    "train_xy_cat = Property(xy_cat_features)\n",
    "\n",
    "train_x_features = TimeSeries(x_num_features[:, :, train_idx])\n",
    "valid_x_features = TimeSeries(x_num_features[:, :, valid_idx])\n",
    "valid_xy_cat = Property(xy_cat_features)\n",
    "\n",
    "train_weight = TimeSeries(weights[:, :, train_idx])\n",
    "valid_weight = TimeSeries(weights[:, :, valid_idx])\n",
    "\n",
    "train_frame = Seq2SeqDataLoader(train_xy, batch_size=16, enc_lens=ENC_LEN, dec_lens=DEC_LEN, use_cuda=True, mode='train', time_free_space=24,\n",
    "                          enc_num_feats=[train_xy_features, train_x_features], dec_num_feats=[train_xy_features], weights=train_weight,\n",
    "                               enc_cat_feats=[train_xy_cat], dec_cat_feats=[train_xy_cat])\n",
    "valid_frame = Seq2SeqDataLoader(valid_xy, batch_size=64, enc_lens=ENC_LEN, dec_lens=DEC_LEN, use_cuda=True, mode='train', time_free_space=0,\n",
    "                         time_interval=48, enc_num_feats=[valid_xy_features, valid_x_features], dec_num_feats=[valid_xy_features],\n",
    "                               weights=valid_weight, dec_cat_feats=[valid_xy_cat], enc_cat_feats=[valid_xy_cat])\n",
    "\n",
    "test_xy = xy[:, :, test_idx]\n",
    "test_xf = np.concatenate([xy_num_features[:, :, test_idx], x_num_features[:, :, test_idx]], axis=1)\n",
    "test_yf = xy_num_features[:, :, test_idx]\n",
    "test_dec_cat = np.repeat(np.expand_dims(xy_cat_features, 2), DEC_LEN, axis=2)\n",
    "test_enc_cat = np.repeat(np.expand_dims(xy_cat_features, 2), ENC_LEN, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 16:30:21]] start training >>>>>>>>>>>  see log: tensorboard --logdir ./power_env\\logs\n",
      "[[04/23/2020 16:30:37]] epoch 1 / 1500, batch 100%, train loss 0.6934, valid loss 0.8635, cost 0.3 min\n",
      "[[04/23/2020 16:30:52]] epoch 2 / 1500, batch 100%, train loss 0.2070, valid loss 0.8207, cost 0.2 min\n",
      "[[04/23/2020 16:31:10]] epoch 3 / 1500, batch 100%, train loss 1.3414, valid loss 0.8928, cost 0.3 min\n",
      "[[04/23/2020 16:31:23]] epoch 4 / 1500, batch 100%, train loss 0.5467, valid loss 0.9882, cost 0.2 min\n",
      "[[04/23/2020 16:31:41]] epoch 5 / 1500, batch 100%, train loss 0.4340, valid loss 1.1661, cost 0.3 min\n",
      "[[04/23/2020 16:32:01]] epoch 6 / 1500, batch 100%, train loss 0.5371, valid loss 1.1690, cost 0.3 min\n",
      "[[04/23/2020 16:32:17]] epoch 7 / 1500, batch 100%, train loss 0.4245, valid loss 0.9368, cost 0.3 min\n",
      "[[04/23/2020 16:32:36]] epoch 8 / 1500, batch 100%, train loss 0.9840, valid loss 0.8528, cost 0.3 min\n",
      "[[04/23/2020 16:32:52]] epoch 9 / 1500, batch 100%, train loss 0.2079, valid loss 0.8230, cost 0.3 min\n",
      "[[04/23/2020 16:33:13]] epoch 10 / 1500, batch 100%, train loss 0.5128, valid loss 0.8155, cost 0.3 min\n",
      "[[04/23/2020 16:33:28]] epoch 11 / 1500, batch 100%, train loss 0.4481, valid loss 0.8217, cost 0.2 min\n",
      "[[04/23/2020 16:33:44]] epoch 12 / 1500, batch 100%, train loss 0.3391, valid loss 0.8161, cost 0.3 min\n",
      "[[04/23/2020 16:34:02]] epoch 13 / 1500, batch 100%, train loss 0.4143, valid loss 0.8119, cost 0.3 min\n",
      "[[04/23/2020 16:34:19]] epoch 14 / 1500, batch 100%, train loss 0.4905, valid loss 0.8105, cost 0.3 min\n",
      "[[04/23/2020 16:34:38]] epoch 15 / 1500, batch 100%, train loss 0.3785, valid loss 0.8042, cost 0.3 min\n",
      "[[04/23/2020 16:34:58]] epoch 16 / 1500, batch 100%, train loss 0.3658, valid loss 0.7868, cost 0.3 min\n",
      "[[04/23/2020 16:35:14]] epoch 17 / 1500, batch 100%, train loss 0.3541, valid loss 0.7532, cost 0.3 min\n",
      "[[04/23/2020 16:35:32]] epoch 18 / 1500, batch 100%, train loss 0.9741, valid loss 0.7302, cost 0.3 min\n",
      "[[04/23/2020 16:35:50]] epoch 19 / 1500, batch 100%, train loss 0.5690, valid loss 0.6660, cost 0.3 min\n",
      "[[04/23/2020 16:36:08]] epoch 20 / 1500, batch 100%, train loss 0.6904, valid loss 0.5644, cost 0.3 min\n",
      "[[04/23/2020 16:36:29]] epoch 21 / 1500, batch 100%, train loss 0.2545, valid loss 0.5552, cost 0.3 min\n",
      "[[04/23/2020 16:36:48]] epoch 22 / 1500, batch 100%, train loss 0.1712, valid loss 0.5199, cost 0.3 min\n",
      "[[04/23/2020 16:37:05]] epoch 23 / 1500, batch 100%, train loss 0.7486, valid loss 0.4805, cost 0.3 min\n",
      "[[04/23/2020 16:37:22]] epoch 24 / 1500, batch 100%, train loss 0.1421, valid loss 0.4403, cost 0.3 min\n",
      "[[04/23/2020 16:37:37]] epoch 25 / 1500, batch 100%, train loss 0.1491, valid loss 0.4209, cost 0.3 min\n",
      "[[04/23/2020 16:37:57]] epoch 26 / 1500, batch 100%, train loss 0.4874, valid loss 0.4180, cost 0.3 min\n",
      "[[04/23/2020 16:38:12]] epoch 27 / 1500, batch 100%, train loss 0.2488, valid loss 0.3971, cost 0.3 min\n",
      "[[04/23/2020 16:38:29]] epoch 28 / 1500, batch 100%, train loss 0.5410, valid loss 0.4083, cost 0.3 min\n",
      "[[04/23/2020 16:38:43]] epoch 29 / 1500, batch 100%, train loss 0.1302, valid loss 0.3967, cost 0.2 min\n",
      "[[04/23/2020 16:38:56]] epoch 30 / 1500, batch 100%, train loss 0.4986, valid loss 0.4092, cost 0.2 min\n",
      "[[04/23/2020 16:39:16]] epoch 31 / 1500, batch 100%, train loss 0.2783, valid loss 0.3821, cost 0.3 min\n",
      "[[04/23/2020 16:39:38]] epoch 32 / 1500, batch 100%, train loss 0.0856, valid loss 0.3927, cost 0.4 min\n",
      "[[04/23/2020 16:39:55]] epoch 33 / 1500, batch 100%, train loss 0.3285, valid loss 0.3899, cost 0.3 min\n",
      "[[04/23/2020 16:40:15]] epoch 34 / 1500, batch 100%, train loss 0.0788, valid loss 0.3869, cost 0.3 min\n",
      "[[04/23/2020 16:40:31]] epoch 35 / 1500, batch 100%, train loss 0.1868, valid loss 0.3920, cost 0.3 min\n",
      "[[04/23/2020 16:40:49]] epoch 36 / 1500, batch 100%, train loss 0.1205, valid loss 0.3834, cost 0.3 min\n",
      "[[04/23/2020 16:41:10]] epoch 37 / 1500, batch 100%, train loss 0.2397, valid loss 0.3732, cost 0.3 min\n",
      "[[04/23/2020 16:41:28]] epoch 38 / 1500, batch 100%, train loss 0.5012, valid loss 0.3755, cost 0.3 min\n",
      "[[04/23/2020 16:41:46]] epoch 39 / 1500, batch 100%, train loss 0.5909, valid loss 0.3916, cost 0.3 min\n",
      "[[04/23/2020 16:42:03]] epoch 40 / 1500, batch 100%, train loss 0.1636, valid loss 0.3585, cost 0.3 min\n",
      "[[04/23/2020 16:42:21]] epoch 41 / 1500, batch 100%, train loss 0.2544, valid loss 0.3592, cost 0.3 min\n",
      "[[04/23/2020 16:42:39]] epoch 42 / 1500, batch 100%, train loss 0.4882, valid loss 0.3874, cost 0.3 min\n",
      "[[04/23/2020 16:43:01]] epoch 43 / 1500, batch 100%, train loss 0.4646, valid loss 0.3939, cost 0.4 min\n",
      "[[04/23/2020 16:43:18]] epoch 44 / 1500, batch 100%, train loss 0.1897, valid loss 0.3961, cost 0.3 min\n",
      "[[04/23/2020 16:43:34]] epoch 45 / 1500, batch 100%, train loss 0.1496, valid loss 0.3955, cost 0.3 min\n",
      "[[04/23/2020 16:43:51]] epoch 46 / 1500, batch 100%, train loss 0.2552, valid loss 0.3728, cost 0.3 min\n",
      "[[04/23/2020 16:44:10]] epoch 47 / 1500, batch 100%, train loss 0.0264, valid loss 0.3651, cost 0.3 min\n",
      "[[04/23/2020 16:44:26]] epoch 48 / 1500, batch 100%, train loss 0.6657, valid loss 0.3556, cost 0.3 min\n",
      "[[04/23/2020 16:44:43]] epoch 49 / 1500, batch 100%, train loss 0.3056, valid loss 0.3521, cost 0.3 min\n",
      "[[04/23/2020 16:45:02]] epoch 50 / 1500, batch 100%, train loss 0.3096, valid loss 0.3532, cost 0.3 min\n",
      "[[04/23/2020 16:45:23]] epoch 51 / 1500, batch 100%, train loss 0.0652, valid loss 0.3611, cost 0.3 min\n",
      "[[04/23/2020 16:45:39]] epoch 52 / 1500, batch 100%, train loss 0.1010, valid loss 0.3617, cost 0.3 min\n",
      "[[04/23/2020 16:45:52]] epoch 53 / 1500, batch 100%, train loss 0.0845, valid loss 0.3568, cost 0.2 min\n",
      "[[04/23/2020 16:46:14]] epoch 54 / 1500, batch 100%, train loss 0.1846, valid loss 0.3709, cost 0.4 min\n",
      "[[04/23/2020 16:46:38]] epoch 55 / 1500, batch 100%, train loss 0.0953, valid loss 0.3703, cost 0.4 min\n",
      "[[04/23/2020 16:47:03]] epoch 56 / 1500, batch 100%, train loss 0.1611, valid loss 0.3713, cost 0.4 min\n",
      "[[04/23/2020 16:47:26]] epoch 57 / 1500, batch 100%, train loss 0.1964, valid loss 0.3766, cost 0.4 min\n",
      "[[04/23/2020 16:47:50]] epoch 58 / 1500, batch 100%, train loss 0.0744, valid loss 0.3758, cost 0.4 min\n",
      "[[04/23/2020 16:48:13]] epoch 59 / 1500, batch 100%, train loss 0.3352, valid loss 0.3802, cost 0.4 min\n",
      "[[04/23/2020 16:48:34]] epoch 60 / 1500, batch 100%, train loss 0.1342, valid loss 0.3775, cost 0.4 min\n",
      "[[04/23/2020 16:48:57]] epoch 61 / 1500, batch 100%, train loss 0.3007, valid loss 0.3826, cost 0.4 min\n",
      "[[04/23/2020 16:49:18]] epoch 62 / 1500, batch 100%, train loss 0.7617, valid loss 0.3735, cost 0.3 min\n",
      "[[04/23/2020 16:49:45]] epoch 63 / 1500, batch 100%, train loss 0.1843, valid loss 0.3699, cost 0.5 min\n",
      "[[04/23/2020 16:50:05]] epoch 64 / 1500, batch 100%, train loss 0.2305, valid loss 0.3686, cost 0.3 min\n",
      "[[04/23/2020 16:50:31]] epoch 65 / 1500, batch 100%, train loss 0.3622, valid loss 0.3694, cost 0.4 min\n",
      "[[04/23/2020 16:50:55]] epoch 66 / 1500, batch 100%, train loss 0.3354, valid loss 0.3680, cost 0.4 min\n",
      "[[04/23/2020 16:51:20]] epoch 67 / 1500, batch 100%, train loss 0.3515, valid loss 0.3696, cost 0.4 min\n",
      "[[04/23/2020 16:51:38]] epoch 68 / 1500, batch 100%, train loss 0.3077, valid loss 0.3611, cost 0.3 min\n",
      "[[04/23/2020 16:52:05]] epoch 69 / 1500, batch 100%, train loss 0.4821, valid loss 0.3668, cost 0.4 min\n",
      "[[04/23/2020 16:52:30]] epoch 70 / 1500, batch 100%, train loss 0.0900, valid loss 0.3644, cost 0.4 min\n",
      "[[04/23/2020 16:52:51]] epoch 71 / 1500, batch 100%, train loss 0.1216, valid loss 0.3675, cost 0.4 min\n",
      "[[04/23/2020 16:53:12]] epoch 72 / 1500, batch 100%, train loss 0.2795, valid loss 0.3679, cost 0.3 min\n",
      "[[04/23/2020 16:53:36]] epoch 73 / 1500, batch 100%, train loss 0.2195, valid loss 0.3699, cost 0.4 min\n",
      "[[04/23/2020 16:54:00]] epoch 74 / 1500, batch 100%, train loss 0.6678, valid loss 0.3768, cost 0.4 min\n",
      "[[04/23/2020 16:54:22]] epoch 75 / 1500, batch 100%, train loss 0.1265, valid loss 0.3691, cost 0.4 min\n",
      "[[04/23/2020 16:54:43]] epoch 76 / 1500, batch 100%, train loss 0.9180, valid loss 0.3639, cost 0.3 min\n",
      "[[04/23/2020 16:55:03]] epoch 77 / 1500, batch 100%, train loss 0.1025, valid loss 0.3632, cost 0.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 16:55:20]] epoch 78 / 1500, batch 100%, train loss 0.1569, valid loss 0.3653, cost 0.3 min\n",
      "[[04/23/2020 16:55:38]] epoch 79 / 1500, batch 100%, train loss 0.4178, valid loss 0.3714, cost 0.3 min\n",
      "[[04/23/2020 16:55:58]] epoch 80 / 1500, batch 100%, train loss 0.2783, valid loss 0.3677, cost 0.3 min\n",
      "[[04/23/2020 16:56:16]] epoch 81 / 1500, batch 100%, train loss 0.1286, valid loss 0.3659, cost 0.3 min\n",
      "[[04/23/2020 16:56:30]] epoch 82 / 1500, batch 100%, train loss 0.2962, valid loss 0.3639, cost 0.2 min\n",
      "[[04/23/2020 16:56:44]] epoch 83 / 1500, batch 100%, train loss 0.5680, valid loss 0.3554, cost 0.2 min\n",
      "[[04/23/2020 16:57:01]] epoch 84 / 1500, batch 100%, train loss 0.1947, valid loss 0.3652, cost 0.3 min\n",
      "[[04/23/2020 16:57:13]] epoch 85 / 1500, batch 100%, train loss 0.3223, valid loss 0.3632, cost 0.2 min\n",
      "[[04/23/2020 16:57:33]] epoch 86 / 1500, batch 100%, train loss 0.1556, valid loss 0.3615, cost 0.3 min\n",
      "[[04/23/2020 16:57:49]] epoch 87 / 1500, batch 100%, train loss 0.1140, valid loss 0.3662, cost 0.3 min\n",
      "[[04/23/2020 16:58:05]] epoch 88 / 1500, batch 100%, train loss 0.1900, valid loss 0.3850, cost 0.3 min\n",
      "[[04/23/2020 16:58:18]] epoch 89 / 1500, batch 100%, train loss 0.1118, valid loss 0.3971, cost 0.2 min\n",
      "[[04/23/2020 16:58:35]] epoch 90 / 1500, batch 100%, train loss 0.6954, valid loss 0.3782, cost 0.3 min\n",
      "[[04/23/2020 16:58:50]] epoch 91 / 1500, batch 100%, train loss 0.0700, valid loss 0.3710, cost 0.3 min\n",
      "[[04/23/2020 16:59:05]] epoch 92 / 1500, batch 100%, train loss 0.0864, valid loss 0.3638, cost 0.2 min\n",
      "[[04/23/2020 16:59:21]] epoch 93 / 1500, batch 100%, train loss 0.0958, valid loss 0.3664, cost 0.3 min\n",
      "[[04/23/2020 16:59:37]] epoch 94 / 1500, batch 100%, train loss 0.4680, valid loss 0.3591, cost 0.3 min\n",
      "[[04/23/2020 16:59:55]] epoch 95 / 1500, batch 100%, train loss 0.0437, valid loss 0.3541, cost 0.3 min\n",
      "[[04/23/2020 17:00:12]] epoch 96 / 1500, batch 100%, train loss 0.1438, valid loss 0.3541, cost 0.3 min\n",
      "[[04/23/2020 17:00:28]] epoch 97 / 1500, batch 100%, train loss 0.1403, valid loss 0.3516, cost 0.3 min\n",
      "[[04/23/2020 17:00:45]] epoch 98 / 1500, batch 100%, train loss 0.3501, valid loss 0.3391, cost 0.3 min\n",
      "[[04/23/2020 17:01:01]] epoch 99 / 1500, batch 100%, train loss 0.3120, valid loss 0.3347, cost 0.3 min\n",
      "[[04/23/2020 17:01:18]] epoch 100 / 1500, batch 100%, train loss 0.2005, valid loss 0.3738, cost 0.3 min\n",
      "[[04/23/2020 17:01:36]] epoch 101 / 1500, batch 100%, train loss 0.2408, valid loss 0.3731, cost 0.3 min\n",
      "[[04/23/2020 17:01:52]] epoch 102 / 1500, batch 100%, train loss 0.1112, valid loss 0.3505, cost 0.3 min\n",
      "[[04/23/2020 17:02:07]] epoch 103 / 1500, batch 100%, train loss 0.3456, valid loss 0.3209, cost 0.2 min\n",
      "[[04/23/2020 17:02:21]] epoch 104 / 1500, batch 100%, train loss 0.4591, valid loss 0.3160, cost 0.2 min\n",
      "[[04/23/2020 17:02:40]] epoch 105 / 1500, batch 100%, train loss 0.7804, valid loss 0.3134, cost 0.3 min\n",
      "[[04/23/2020 17:02:57]] epoch 106 / 1500, batch 100%, train loss 0.1337, valid loss 0.3337, cost 0.3 min\n",
      "[[04/23/2020 17:03:14]] epoch 107 / 1500, batch 100%, train loss 0.0851, valid loss 0.3548, cost 0.3 min\n",
      "[[04/23/2020 17:03:29]] epoch 108 / 1500, batch 100%, train loss 0.1171, valid loss 0.3816, cost 0.3 min\n",
      "[[04/23/2020 17:03:45]] epoch 109 / 1500, batch 100%, train loss 0.1028, valid loss 0.3863, cost 0.3 min\n",
      "[[04/23/2020 17:04:04]] epoch 110 / 1500, batch 100%, train loss 0.3103, valid loss 0.3412, cost 0.3 min\n",
      "[[04/23/2020 17:04:18]] epoch 111 / 1500, batch 100%, train loss 0.3876, valid loss 0.3726, cost 0.2 min\n",
      "[[04/23/2020 17:04:30]] epoch 112 / 1500, batch 100%, train loss 0.1410, valid loss 0.4054, cost 0.2 min\n",
      "[[04/23/2020 17:04:47]] epoch 113 / 1500, batch 100%, train loss 0.1332, valid loss 0.3998, cost 0.3 min\n",
      "[[04/23/2020 17:05:05]] epoch 114 / 1500, batch 100%, train loss 0.1377, valid loss 0.3957, cost 0.3 min\n",
      "[[04/23/2020 17:05:24]] epoch 115 / 1500, batch 100%, train loss 0.6838, valid loss 0.4008, cost 0.3 min\n",
      "[[04/23/2020 17:05:43]] epoch 116 / 1500, batch 100%, train loss 0.2995, valid loss 0.3756, cost 0.3 min\n",
      "[[04/23/2020 17:05:59]] epoch 117 / 1500, batch 100%, train loss 0.0694, valid loss 0.3833, cost 0.3 min\n",
      "[[04/23/2020 17:06:15]] epoch 118 / 1500, batch 100%, train loss 0.2407, valid loss 0.3707, cost 0.3 min\n",
      "[[04/23/2020 17:06:35]] epoch 119 / 1500, batch 100%, train loss 0.3679, valid loss 0.3407, cost 0.3 min\n",
      "[[04/23/2020 17:06:50]] epoch 120 / 1500, batch 100%, train loss 0.3008, valid loss 0.4015, cost 0.2 min\n",
      "[[04/23/2020 17:07:06]] epoch 121 / 1500, batch 100%, train loss 0.4165, valid loss 0.3449, cost 0.3 min\n",
      "[[04/23/2020 17:07:22]] epoch 122 / 1500, batch 100%, train loss 0.0657, valid loss 0.4264, cost 0.3 min\n",
      "[[04/23/2020 17:07:36]] epoch 123 / 1500, batch 100%, train loss 0.5057, valid loss 0.4308, cost 0.2 min\n",
      "[[04/23/2020 17:07:51]] epoch 124 / 1500, batch 100%, train loss 0.2597, valid loss 0.3685, cost 0.2 min\n",
      "[[04/23/2020 17:08:08]] epoch 125 / 1500, batch 100%, train loss 0.4034, valid loss 0.4167, cost 0.3 min\n",
      "[[04/23/2020 17:08:20]] epoch 126 / 1500, batch 100%, train loss 0.1511, valid loss 0.4531, cost 0.2 min\n",
      "[[04/23/2020 17:08:39]] epoch 127 / 1500, batch 100%, train loss 0.1539, valid loss 0.4665, cost 0.3 min\n",
      "[[04/23/2020 17:09:00]] epoch 128 / 1500, batch 100%, train loss 0.2602, valid loss 0.4256, cost 0.3 min\n",
      "[[04/23/2020 17:09:14]] epoch 129 / 1500, batch 100%, train loss 0.1876, valid loss 0.3542, cost 0.2 min\n",
      "[[04/23/2020 17:09:29]] epoch 130 / 1500, batch 100%, train loss 0.4376, valid loss 0.3248, cost 0.2 min\n",
      "[[04/23/2020 17:09:44]] epoch 131 / 1500, batch 100%, train loss 0.2164, valid loss 0.3587, cost 0.2 min\n",
      "[[04/23/2020 17:10:06]] epoch 132 / 1500, batch 100%, train loss 0.4839, valid loss 0.3939, cost 0.4 min\n",
      "[[04/23/2020 17:10:20]] epoch 133 / 1500, batch 100%, train loss 0.1479, valid loss 0.4113, cost 0.2 min\n",
      "[[04/23/2020 17:10:35]] epoch 134 / 1500, batch 100%, train loss 0.3060, valid loss 0.3436, cost 0.3 min\n",
      "[[04/23/2020 17:10:49]] epoch 135 / 1500, batch 100%, train loss 0.1152, valid loss 0.3125, cost 0.2 min\n",
      "[[04/23/2020 17:11:11]] epoch 136 / 1500, batch 100%, train loss 0.4060, valid loss 0.3515, cost 0.4 min\n",
      "[[04/23/2020 17:11:32]] epoch 137 / 1500, batch 100%, train loss 0.3902, valid loss 0.3300, cost 0.3 min\n",
      "[[04/23/2020 17:11:46]] epoch 138 / 1500, batch 100%, train loss 0.1580, valid loss 0.4115, cost 0.2 min\n",
      "[[04/23/2020 17:12:03]] epoch 139 / 1500, batch 100%, train loss 0.6030, valid loss 0.4229, cost 0.3 min\n",
      "[[04/23/2020 17:12:17]] epoch 140 / 1500, batch 100%, train loss 0.0329, valid loss 0.3663, cost 0.2 min\n",
      "[[04/23/2020 17:12:35]] epoch 141 / 1500, batch 100%, train loss 0.1666, valid loss 0.3397, cost 0.3 min\n",
      "[[04/23/2020 17:12:49]] epoch 142 / 1500, batch 100%, train loss 0.6554, valid loss 0.3554, cost 0.2 min\n",
      "[[04/23/2020 17:13:06]] epoch 143 / 1500, batch 100%, train loss 0.2648, valid loss 0.3450, cost 0.3 min\n",
      "[[04/23/2020 17:13:23]] epoch 144 / 1500, batch 100%, train loss 0.1187, valid loss 0.4086, cost 0.3 min\n",
      "[[04/23/2020 17:13:42]] epoch 145 / 1500, batch 100%, train loss 0.1925, valid loss 0.4528, cost 0.3 min\n",
      "[[04/23/2020 17:13:59]] epoch 146 / 1500, batch 100%, train loss 0.6538, valid loss 0.4178, cost 0.3 min\n",
      "[[04/23/2020 17:14:19]] epoch 147 / 1500, batch 100%, train loss 0.8439, valid loss 0.3412, cost 0.3 min\n",
      "[[04/23/2020 17:14:33]] epoch 148 / 1500, batch 100%, train loss 0.3193, valid loss 0.3491, cost 0.2 min\n",
      "[[04/23/2020 17:14:51]] epoch 149 / 1500, batch 100%, train loss 0.1475, valid loss 0.3381, cost 0.3 min\n",
      "[[04/23/2020 17:15:07]] epoch 150 / 1500, batch 100%, train loss 0.1816, valid loss 0.3617, cost 0.3 min\n",
      "[[04/23/2020 17:15:27]] epoch 151 / 1500, batch 100%, train loss 0.1419, valid loss 0.3915, cost 0.3 min\n",
      "[[04/23/2020 17:15:43]] epoch 152 / 1500, batch 100%, train loss 0.0776, valid loss 0.4052, cost 0.3 min\n",
      "[[04/23/2020 17:15:59]] epoch 153 / 1500, batch 100%, train loss 0.2275, valid loss 0.4054, cost 0.3 min\n",
      "[[04/23/2020 17:16:16]] epoch 154 / 1500, batch 100%, train loss 0.3287, valid loss 0.3631, cost 0.3 min\n",
      "[[04/23/2020 17:16:35]] epoch 155 / 1500, batch 100%, train loss 0.2706, valid loss 0.3193, cost 0.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 17:16:52]] epoch 156 / 1500, batch 100%, train loss 0.5052, valid loss 0.3210, cost 0.3 min\n",
      "[[04/23/2020 17:17:12]] epoch 157 / 1500, batch 100%, train loss 0.1774, valid loss 0.3771, cost 0.3 min\n",
      "[[04/23/2020 17:17:32]] epoch 158 / 1500, batch 100%, train loss 0.1258, valid loss 0.4115, cost 0.3 min\n",
      "[[04/23/2020 17:17:47]] epoch 159 / 1500, batch 100%, train loss 0.3019, valid loss 0.3321, cost 0.2 min\n",
      "[[04/23/2020 17:18:09]] epoch 160 / 1500, batch 100%, train loss 0.3695, valid loss 0.3193, cost 0.4 min\n",
      "[[04/23/2020 17:18:25]] epoch 161 / 1500, batch 100%, train loss 0.2669, valid loss 0.3323, cost 0.3 min\n",
      "[[04/23/2020 17:18:44]] epoch 162 / 1500, batch 100%, train loss 0.3060, valid loss 0.3564, cost 0.3 min\n",
      "[[04/23/2020 17:18:58]] epoch 163 / 1500, batch 100%, train loss 0.1231, valid loss 0.3642, cost 0.2 min\n",
      "[[04/23/2020 17:19:12]] epoch 164 / 1500, batch 100%, train loss 0.2902, valid loss 0.3475, cost 0.2 min\n",
      "[[04/23/2020 17:19:31]] epoch 165 / 1500, batch 100%, train loss 0.1597, valid loss 0.3262, cost 0.3 min\n",
      "[[04/23/2020 17:19:48]] epoch 166 / 1500, batch 100%, train loss 0.2272, valid loss 0.3297, cost 0.3 min\n",
      "[[04/23/2020 17:20:01]] epoch 167 / 1500, batch 100%, train loss 0.4279, valid loss 0.3263, cost 0.2 min\n",
      "[[04/23/2020 17:20:14]] epoch 168 / 1500, batch 100%, train loss 0.1328, valid loss 0.3146, cost 0.2 min\n",
      "[[04/23/2020 17:20:31]] epoch 169 / 1500, batch 100%, train loss 0.3951, valid loss 0.3132, cost 0.3 min\n",
      "[[04/23/2020 17:20:50]] epoch 170 / 1500, batch 100%, train loss 0.0768, valid loss 0.3132, cost 0.3 min\n",
      "[[04/23/2020 17:21:08]] epoch 171 / 1500, batch 100%, train loss 0.1962, valid loss 0.3224, cost 0.3 min\n",
      "[[04/23/2020 17:21:27]] epoch 172 / 1500, batch 100%, train loss 0.3094, valid loss 0.3225, cost 0.3 min\n",
      "[[04/23/2020 17:21:44]] epoch 173 / 1500, batch 100%, train loss 0.1890, valid loss 0.3180, cost 0.3 min\n",
      "[[04/23/2020 17:22:01]] epoch 174 / 1500, batch 100%, train loss 0.2227, valid loss 0.3163, cost 0.3 min\n",
      "[[04/23/2020 17:22:14]] epoch 175 / 1500, batch 100%, train loss 0.0767, valid loss 0.3132, cost 0.2 min\n",
      "[[04/23/2020 17:22:35]] epoch 176 / 1500, batch 100%, train loss 0.0433, valid loss 0.3126, cost 0.3 min\n",
      "[[04/23/2020 17:22:45]] epoch 177 / 1500, batch 100%, train loss 0.0536, valid loss 0.3147, cost 0.2 min\n",
      "[[04/23/2020 17:23:02]] epoch 178 / 1500, batch 100%, train loss 0.1916, valid loss 0.3144, cost 0.3 min\n",
      "[[04/23/2020 17:23:17]] epoch 179 / 1500, batch 100%, train loss 0.4007, valid loss 0.3166, cost 0.2 min\n",
      "[[04/23/2020 17:23:32]] epoch 180 / 1500, batch 100%, train loss 0.2757, valid loss 0.3130, cost 0.3 min\n",
      "[[04/23/2020 17:23:50]] epoch 181 / 1500, batch 100%, train loss 0.1555, valid loss 0.3084, cost 0.3 min\n",
      "[[04/23/2020 17:24:08]] epoch 182 / 1500, batch 100%, train loss 0.1340, valid loss 0.3083, cost 0.3 min\n",
      "[[04/23/2020 17:24:26]] epoch 183 / 1500, batch 100%, train loss 0.2163, valid loss 0.3152, cost 0.3 min\n",
      "[[04/23/2020 17:24:40]] epoch 184 / 1500, batch 100%, train loss 0.0365, valid loss 0.3141, cost 0.2 min\n",
      "[[04/23/2020 17:24:56]] epoch 185 / 1500, batch 100%, train loss 0.1289, valid loss 0.3183, cost 0.3 min\n",
      "[[04/23/2020 17:25:13]] epoch 186 / 1500, batch 100%, train loss 0.1177, valid loss 0.3150, cost 0.3 min\n",
      "[[04/23/2020 17:25:28]] epoch 187 / 1500, batch 100%, train loss 0.1266, valid loss 0.3175, cost 0.3 min\n",
      "[[04/23/2020 17:25:44]] epoch 188 / 1500, batch 100%, train loss 0.1704, valid loss 0.3115, cost 0.3 min\n",
      "[[04/23/2020 17:26:00]] epoch 189 / 1500, batch 100%, train loss 0.2243, valid loss 0.3185, cost 0.3 min\n",
      "[[04/23/2020 17:26:15]] epoch 190 / 1500, batch 100%, train loss 0.1030, valid loss 0.3199, cost 0.3 min\n",
      "[[04/23/2020 17:26:30]] epoch 191 / 1500, batch 100%, train loss 0.0952, valid loss 0.3167, cost 0.2 min\n",
      "[[04/23/2020 17:26:49]] epoch 192 / 1500, batch 100%, train loss 0.0950, valid loss 0.3232, cost 0.3 min\n",
      "[[04/23/2020 17:27:06]] epoch 193 / 1500, batch 100%, train loss 0.4816, valid loss 0.3164, cost 0.3 min\n",
      "[[04/23/2020 17:27:23]] epoch 194 / 1500, batch 100%, train loss 0.0733, valid loss 0.3203, cost 0.3 min\n",
      "[[04/23/2020 17:27:40]] epoch 195 / 1500, batch 100%, train loss 0.0869, valid loss 0.3162, cost 0.3 min\n",
      "[[04/23/2020 17:27:58]] epoch 196 / 1500, batch 100%, train loss 0.1322, valid loss 0.3170, cost 0.3 min\n",
      "[[04/23/2020 17:28:12]] epoch 197 / 1500, batch 100%, train loss 0.1543, valid loss 0.3185, cost 0.2 min\n",
      "[[04/23/2020 17:28:28]] epoch 198 / 1500, batch 100%, train loss 0.1902, valid loss 0.3198, cost 0.3 min\n",
      "[[04/23/2020 17:28:43]] epoch 199 / 1500, batch 100%, train loss 0.0992, valid loss 0.3170, cost 0.3 min\n",
      "[[04/23/2020 17:29:01]] epoch 200 / 1500, batch 100%, train loss 0.4456, valid loss 0.3157, cost 0.3 min\n",
      "[[04/23/2020 17:29:18]] epoch 201 / 1500, batch 100%, train loss 0.1260, valid loss 0.3140, cost 0.3 min\n",
      "[[04/23/2020 17:29:34]] epoch 202 / 1500, batch 100%, train loss 0.3554, valid loss 0.3149, cost 0.3 min\n",
      "[[04/23/2020 17:29:53]] epoch 203 / 1500, batch 100%, train loss 0.0955, valid loss 0.3172, cost 0.3 min\n",
      "[[04/23/2020 17:30:09]] epoch 204 / 1500, batch 100%, train loss 0.8818, valid loss 0.3119, cost 0.3 min\n",
      "[[04/23/2020 17:30:23]] epoch 205 / 1500, batch 100%, train loss 0.5096, valid loss 0.3086, cost 0.2 min\n",
      "[[04/23/2020 17:30:41]] epoch 206 / 1500, batch 100%, train loss 0.0477, valid loss 0.3123, cost 0.3 min\n",
      "[[04/23/2020 17:30:57]] epoch 207 / 1500, batch 100%, train loss 0.3620, valid loss 0.3098, cost 0.3 min\n",
      "[[04/23/2020 17:31:12]] epoch 208 / 1500, batch 100%, train loss 0.1592, valid loss 0.3054, cost 0.2 min\n",
      "[[04/23/2020 17:31:28]] epoch 209 / 1500, batch 100%, train loss 0.5508, valid loss 0.3161, cost 0.3 min\n",
      "[[04/23/2020 17:31:49]] epoch 210 / 1500, batch 100%, train loss 0.3604, valid loss 0.3222, cost 0.3 min\n",
      "[[04/23/2020 17:32:09]] epoch 211 / 1500, batch 100%, train loss 0.1118, valid loss 0.3304, cost 0.3 min\n",
      "[[04/23/2020 17:32:27]] epoch 212 / 1500, batch 100%, train loss 0.4151, valid loss 0.3245, cost 0.3 min\n",
      "[[04/23/2020 17:32:45]] epoch 213 / 1500, batch 100%, train loss 0.0771, valid loss 0.3195, cost 0.3 min\n",
      "[[04/23/2020 17:33:03]] epoch 214 / 1500, batch 100%, train loss 0.4470, valid loss 0.3074, cost 0.3 min\n",
      "[[04/23/2020 17:33:21]] epoch 215 / 1500, batch 100%, train loss 0.3099, valid loss 0.3108, cost 0.3 min\n",
      "[[04/23/2020 17:33:36]] epoch 216 / 1500, batch 100%, train loss 0.3136, valid loss 0.3126, cost 0.2 min\n",
      "[[04/23/2020 17:33:51]] epoch 217 / 1500, batch 100%, train loss 0.1329, valid loss 0.3157, cost 0.2 min\n",
      "[[04/23/2020 17:34:07]] epoch 218 / 1500, batch 100%, train loss 0.2922, valid loss 0.3128, cost 0.3 min\n",
      "[[04/23/2020 17:34:24]] epoch 219 / 1500, batch 100%, train loss 0.5545, valid loss 0.3216, cost 0.3 min\n",
      "[[04/23/2020 17:34:36]] epoch 220 / 1500, batch 100%, train loss 0.5019, valid loss 0.3353, cost 0.2 min\n",
      "[[04/23/2020 17:34:51]] epoch 221 / 1500, batch 100%, train loss 0.0989, valid loss 0.3379, cost 0.3 min\n",
      "[[04/23/2020 17:35:08]] epoch 222 / 1500, batch 100%, train loss 0.1909, valid loss 0.3388, cost 0.3 min\n",
      "[[04/23/2020 17:35:26]] epoch 223 / 1500, batch 100%, train loss 0.3881, valid loss 0.3363, cost 0.3 min\n",
      "[[04/23/2020 17:35:42]] epoch 224 / 1500, batch 100%, train loss 0.2016, valid loss 0.3399, cost 0.3 min\n",
      "[[04/23/2020 17:35:59]] epoch 225 / 1500, batch 100%, train loss 0.0697, valid loss 0.3321, cost 0.3 min\n",
      "[[04/23/2020 17:36:13]] epoch 226 / 1500, batch 100%, train loss 0.1567, valid loss 0.3155, cost 0.2 min\n",
      "[[04/23/2020 17:36:33]] epoch 227 / 1500, batch 100%, train loss 0.1176, valid loss 0.3169, cost 0.3 min\n",
      "[[04/23/2020 17:36:45]] epoch 228 / 1500, batch 100%, train loss 0.0506, valid loss 0.3195, cost 0.2 min\n",
      "[[04/23/2020 17:37:03]] epoch 229 / 1500, batch 100%, train loss 0.2211, valid loss 0.3176, cost 0.3 min\n",
      "[[04/23/2020 17:37:20]] epoch 230 / 1500, batch 100%, train loss 0.1023, valid loss 0.3185, cost 0.3 min\n",
      "[[04/23/2020 17:37:38]] epoch 231 / 1500, batch 100%, train loss 0.1591, valid loss 0.3108, cost 0.3 min\n",
      "[[04/23/2020 17:37:55]] epoch 232 / 1500, batch 100%, train loss 0.4221, valid loss 0.3173, cost 0.3 min\n",
      "[[04/23/2020 17:38:12]] epoch 233 / 1500, batch 100%, train loss 0.0746, valid loss 0.3470, cost 0.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 17:38:29]] epoch 234 / 1500, batch 100%, train loss 0.0636, valid loss 0.3666, cost 0.3 min\n",
      "[[04/23/2020 17:38:46]] epoch 235 / 1500, batch 100%, train loss 0.4061, valid loss 0.3566, cost 0.3 min\n",
      "[[04/23/2020 17:39:04]] epoch 236 / 1500, batch 100%, train loss 0.3101, valid loss 0.3280, cost 0.3 min\n",
      "[[04/23/2020 17:39:22]] epoch 237 / 1500, batch 100%, train loss 0.4092, valid loss 0.3196, cost 0.3 min\n",
      "[[04/23/2020 17:39:40]] epoch 238 / 1500, batch 100%, train loss 0.1292, valid loss 0.3145, cost 0.3 min\n",
      "[[04/23/2020 17:40:00]] epoch 239 / 1500, batch 100%, train loss 0.2674, valid loss 0.3142, cost 0.3 min\n",
      "[[04/23/2020 17:40:16]] epoch 240 / 1500, batch 100%, train loss 0.5429, valid loss 0.3109, cost 0.3 min\n",
      "[[04/23/2020 17:40:34]] epoch 241 / 1500, batch 100%, train loss 0.1703, valid loss 0.3158, cost 0.3 min\n",
      "[[04/23/2020 17:40:49]] epoch 242 / 1500, batch 100%, train loss 0.1773, valid loss 0.3251, cost 0.3 min\n",
      "[[04/23/2020 17:41:09]] epoch 243 / 1500, batch 100%, train loss 0.1896, valid loss 0.3369, cost 0.3 min\n",
      "[[04/23/2020 17:41:26]] epoch 244 / 1500, batch 100%, train loss 0.0641, valid loss 0.3410, cost 0.3 min\n",
      "[[04/23/2020 17:41:43]] epoch 245 / 1500, batch 100%, train loss 0.3593, valid loss 0.3557, cost 0.3 min\n",
      "[[04/23/2020 17:41:57]] epoch 246 / 1500, batch 100%, train loss 0.1197, valid loss 0.3662, cost 0.2 min\n",
      "[[04/23/2020 17:42:14]] epoch 247 / 1500, batch 100%, train loss 0.0993, valid loss 0.3698, cost 0.3 min\n",
      "[[04/23/2020 17:42:26]] epoch 248 / 1500, batch 100%, train loss 0.3074, valid loss 0.3651, cost 0.2 min\n",
      "[[04/23/2020 17:42:43]] epoch 249 / 1500, batch 100%, train loss 0.0897, valid loss 0.3660, cost 0.3 min\n",
      "[[04/23/2020 17:42:56]] epoch 250 / 1500, batch 100%, train loss 0.0502, valid loss 0.3635, cost 0.2 min\n",
      "[[04/23/2020 17:43:13]] epoch 251 / 1500, batch 100%, train loss 0.1904, valid loss 0.3386, cost 0.3 min\n",
      "[[04/23/2020 17:43:30]] epoch 252 / 1500, batch 100%, train loss 0.2705, valid loss 0.3047, cost 0.3 min\n",
      "[[04/23/2020 17:43:48]] epoch 253 / 1500, batch 100%, train loss 0.0869, valid loss 0.2847, cost 0.3 min\n",
      "[[04/23/2020 17:44:05]] epoch 254 / 1500, batch 100%, train loss 0.1116, valid loss 0.3044, cost 0.3 min\n",
      "[[04/23/2020 17:44:23]] epoch 255 / 1500, batch 100%, train loss 0.8524, valid loss 0.3945, cost 0.3 min\n",
      "[[04/23/2020 17:44:38]] epoch 256 / 1500, batch 100%, train loss 0.2277, valid loss 0.5941, cost 0.2 min\n",
      "[[04/23/2020 17:44:53]] epoch 257 / 1500, batch 100%, train loss 0.3949, valid loss 0.4327, cost 0.3 min\n",
      "[[04/23/2020 17:45:11]] epoch 258 / 1500, batch 100%, train loss 0.1842, valid loss 0.3988, cost 0.3 min\n",
      "[[04/23/2020 17:45:30]] epoch 259 / 1500, batch 100%, train loss 0.2671, valid loss 0.3902, cost 0.3 min\n",
      "[[04/23/2020 17:45:46]] epoch 260 / 1500, batch 100%, train loss 0.2200, valid loss 0.3701, cost 0.3 min\n",
      "[[04/23/2020 17:46:03]] epoch 261 / 1500, batch 100%, train loss 0.4824, valid loss 0.3298, cost 0.3 min\n",
      "[[04/23/2020 17:46:18]] epoch 262 / 1500, batch 100%, train loss 0.0827, valid loss 0.3212, cost 0.3 min\n",
      "[[04/23/2020 17:46:32]] epoch 263 / 1500, batch 100%, train loss 0.1000, valid loss 0.3166, cost 0.2 min\n",
      "[[04/23/2020 17:46:51]] epoch 264 / 1500, batch 100%, train loss 0.2531, valid loss 0.3266, cost 0.3 min\n",
      "[[04/23/2020 17:47:05]] epoch 265 / 1500, batch 100%, train loss 0.2473, valid loss 0.3255, cost 0.2 min\n",
      "[[04/23/2020 17:47:21]] epoch 266 / 1500, batch 100%, train loss 0.1535, valid loss 0.3266, cost 0.3 min\n",
      "[[04/23/2020 17:47:39]] epoch 267 / 1500, batch 100%, train loss 0.6222, valid loss 0.3375, cost 0.3 min\n",
      "[[04/23/2020 17:47:57]] epoch 268 / 1500, batch 100%, train loss 0.3146, valid loss 0.3564, cost 0.3 min\n",
      "[[04/23/2020 17:48:13]] epoch 269 / 1500, batch 100%, train loss 0.3567, valid loss 0.3361, cost 0.3 min\n",
      "[[04/23/2020 17:48:28]] epoch 270 / 1500, batch 100%, train loss 0.0888, valid loss 0.3183, cost 0.2 min\n",
      "[[04/23/2020 17:48:44]] epoch 271 / 1500, batch 100%, train loss 0.0871, valid loss 0.3031, cost 0.3 min\n",
      "[[04/23/2020 17:48:57]] epoch 272 / 1500, batch 100%, train loss 0.2593, valid loss 0.2837, cost 0.2 min\n",
      "[[04/23/2020 17:49:16]] epoch 273 / 1500, batch 100%, train loss 0.4083, valid loss 0.2896, cost 0.3 min\n",
      "[[04/23/2020 17:49:32]] epoch 274 / 1500, batch 100%, train loss 0.0762, valid loss 0.2993, cost 0.3 min\n",
      "[[04/23/2020 17:49:48]] epoch 275 / 1500, batch 100%, train loss 0.1898, valid loss 0.3070, cost 0.3 min\n",
      "[[04/23/2020 17:50:04]] epoch 276 / 1500, batch 100%, train loss 0.2686, valid loss 0.2932, cost 0.3 min\n",
      "[[04/23/2020 17:50:19]] epoch 277 / 1500, batch 100%, train loss 0.1334, valid loss 0.3044, cost 0.3 min\n",
      "[[04/23/2020 17:50:33]] epoch 278 / 1500, batch 100%, train loss 0.3949, valid loss 0.3587, cost 0.2 min\n",
      "[[04/23/2020 17:50:53]] epoch 279 / 1500, batch 100%, train loss 0.1133, valid loss 0.3941, cost 0.3 min\n",
      "[[04/23/2020 17:51:12]] epoch 280 / 1500, batch 100%, train loss 0.1814, valid loss 0.3999, cost 0.3 min\n",
      "[[04/23/2020 17:51:30]] epoch 281 / 1500, batch 100%, train loss 0.0916, valid loss 0.3864, cost 0.3 min\n",
      "[[04/23/2020 17:51:48]] epoch 282 / 1500, batch 100%, train loss 0.1366, valid loss 0.3820, cost 0.3 min\n",
      "[[04/23/2020 17:52:02]] epoch 283 / 1500, batch 100%, train loss 0.2020, valid loss 0.3731, cost 0.2 min\n",
      "[[04/23/2020 17:52:20]] epoch 284 / 1500, batch 100%, train loss 0.1926, valid loss 0.3298, cost 0.3 min\n",
      "[[04/23/2020 17:52:36]] epoch 285 / 1500, batch 100%, train loss 0.4973, valid loss 0.2951, cost 0.3 min\n",
      "[[04/23/2020 17:52:53]] epoch 286 / 1500, batch 100%, train loss 0.2239, valid loss 0.2882, cost 0.3 min\n",
      "[[04/23/2020 17:53:13]] epoch 287 / 1500, batch 100%, train loss 0.1183, valid loss 0.2893, cost 0.3 min\n",
      "[[04/23/2020 17:53:34]] epoch 288 / 1500, batch 100%, train loss 0.2136, valid loss 0.2888, cost 0.3 min\n",
      "[[04/23/2020 17:53:51]] epoch 289 / 1500, batch 100%, train loss 0.4103, valid loss 0.2965, cost 0.3 min\n",
      "[[04/23/2020 17:54:10]] epoch 290 / 1500, batch 100%, train loss 0.1153, valid loss 0.3064, cost 0.3 min\n",
      "[[04/23/2020 17:54:27]] epoch 291 / 1500, batch 100%, train loss 0.1054, valid loss 0.3122, cost 0.3 min\n",
      "[[04/23/2020 17:54:41]] epoch 292 / 1500, batch 100%, train loss 0.2071, valid loss 0.3064, cost 0.2 min\n",
      "[[04/23/2020 17:54:59]] epoch 293 / 1500, batch 100%, train loss 0.1604, valid loss 0.2983, cost 0.3 min\n",
      "[[04/23/2020 17:55:19]] epoch 294 / 1500, batch 100%, train loss 0.3764, valid loss 0.2954, cost 0.3 min\n",
      "[[04/23/2020 17:55:37]] epoch 295 / 1500, batch 100%, train loss 0.3455, valid loss 0.3052, cost 0.3 min\n",
      "[[04/23/2020 17:55:50]] epoch 296 / 1500, batch 100%, train loss 0.4170, valid loss 0.3010, cost 0.2 min\n",
      "[[04/23/2020 17:56:08]] epoch 297 / 1500, batch 100%, train loss 0.2739, valid loss 0.2936, cost 0.3 min\n",
      "[[04/23/2020 17:56:23]] epoch 298 / 1500, batch 100%, train loss 0.2413, valid loss 0.2956, cost 0.2 min\n",
      "[[04/23/2020 17:56:37]] epoch 299 / 1500, batch 100%, train loss 0.1278, valid loss 0.2890, cost 0.2 min\n",
      "[[04/23/2020 17:56:54]] epoch 300 / 1500, batch 100%, train loss 0.1475, valid loss 0.2837, cost 0.3 min\n",
      "[[04/23/2020 17:57:10]] epoch 301 / 1500, batch 100%, train loss 0.2153, valid loss 0.2891, cost 0.3 min\n",
      "[[04/23/2020 17:57:26]] epoch 302 / 1500, batch 100%, train loss 0.2852, valid loss 0.2950, cost 0.3 min\n",
      "[[04/23/2020 17:57:44]] epoch 303 / 1500, batch 100%, train loss 0.2033, valid loss 0.3052, cost 0.3 min\n",
      "[[04/23/2020 17:58:04]] epoch 304 / 1500, batch 100%, train loss 0.1500, valid loss 0.3062, cost 0.3 min\n",
      "[[04/23/2020 17:58:20]] epoch 305 / 1500, batch 100%, train loss 0.7210, valid loss 0.3001, cost 0.3 min\n",
      "[[04/23/2020 17:58:36]] epoch 306 / 1500, batch 100%, train loss 0.1103, valid loss 0.2952, cost 0.3 min\n",
      "[[04/23/2020 17:58:49]] epoch 307 / 1500, batch 100%, train loss 0.2144, valid loss 0.2970, cost 0.2 min\n",
      "[[04/23/2020 17:59:04]] epoch 308 / 1500, batch 100%, train loss 0.2629, valid loss 0.2919, cost 0.3 min\n",
      "[[04/23/2020 17:59:20]] epoch 309 / 1500, batch 100%, train loss 0.0859, valid loss 0.2879, cost 0.3 min\n",
      "[[04/23/2020 17:59:38]] epoch 310 / 1500, batch 100%, train loss 0.2181, valid loss 0.2842, cost 0.3 min\n",
      "[[04/23/2020 17:59:52]] epoch 311 / 1500, batch 100%, train loss 0.1137, valid loss 0.2861, cost 0.2 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 18:00:12]] epoch 312 / 1500, batch 100%, train loss 0.1633, valid loss 0.2888, cost 0.3 min\n",
      "[[04/23/2020 18:00:28]] epoch 313 / 1500, batch 100%, train loss 0.0879, valid loss 0.2892, cost 0.3 min\n",
      "[[04/23/2020 18:00:44]] epoch 314 / 1500, batch 100%, train loss 0.1704, valid loss 0.2859, cost 0.3 min\n",
      "[[04/23/2020 18:00:59]] epoch 315 / 1500, batch 100%, train loss 0.1624, valid loss 0.2851, cost 0.3 min\n",
      "[[04/23/2020 18:01:13]] epoch 316 / 1500, batch 100%, train loss 0.2420, valid loss 0.2822, cost 0.2 min\n",
      "[[04/23/2020 18:01:29]] epoch 317 / 1500, batch 100%, train loss 0.0917, valid loss 0.2820, cost 0.3 min\n",
      "[[04/23/2020 18:01:42]] epoch 318 / 1500, batch 100%, train loss 0.3001, valid loss 0.2937, cost 0.2 min\n",
      "[[04/23/2020 18:01:59]] epoch 319 / 1500, batch 100%, train loss 0.1528, valid loss 0.2915, cost 0.3 min\n",
      "[[04/23/2020 18:02:17]] epoch 320 / 1500, batch 100%, train loss 0.0635, valid loss 0.2831, cost 0.3 min\n",
      "[[04/23/2020 18:02:37]] epoch 321 / 1500, batch 100%, train loss 0.2351, valid loss 0.2855, cost 0.3 min\n",
      "[[04/23/2020 18:02:49]] epoch 322 / 1500, batch 100%, train loss 0.0621, valid loss 0.2857, cost 0.2 min\n",
      "[[04/23/2020 18:03:09]] epoch 323 / 1500, batch 100%, train loss 0.1418, valid loss 0.2875, cost 0.3 min\n",
      "[[04/23/2020 18:03:26]] epoch 324 / 1500, batch 100%, train loss 0.2430, valid loss 0.2817, cost 0.3 min\n",
      "[[04/23/2020 18:03:42]] epoch 325 / 1500, batch 100%, train loss 0.2009, valid loss 0.2849, cost 0.3 min\n",
      "[[04/23/2020 18:03:58]] epoch 326 / 1500, batch 100%, train loss 0.1909, valid loss 0.2886, cost 0.3 min\n",
      "[[04/23/2020 18:04:12]] epoch 327 / 1500, batch 100%, train loss 0.1619, valid loss 0.2784, cost 0.2 min\n",
      "[[04/23/2020 18:04:24]] epoch 328 / 1500, batch 100%, train loss 0.0498, valid loss 0.2821, cost 0.2 min\n",
      "[[04/23/2020 18:04:42]] epoch 329 / 1500, batch 100%, train loss 0.2801, valid loss 0.2864, cost 0.3 min\n",
      "[[04/23/2020 18:04:58]] epoch 330 / 1500, batch 100%, train loss 0.0469, valid loss 0.2835, cost 0.3 min\n",
      "[[04/23/2020 18:05:19]] epoch 331 / 1500, batch 100%, train loss 0.1905, valid loss 0.2857, cost 0.4 min\n",
      "[[04/23/2020 18:05:34]] epoch 332 / 1500, batch 100%, train loss 0.2828, valid loss 0.2859, cost 0.2 min\n",
      "[[04/23/2020 18:05:51]] epoch 333 / 1500, batch 100%, train loss 0.1379, valid loss 0.2916, cost 0.3 min\n",
      "[[04/23/2020 18:06:04]] epoch 334 / 1500, batch 100%, train loss 0.0895, valid loss 0.2920, cost 0.2 min\n",
      "[[04/23/2020 18:06:18]] epoch 335 / 1500, batch 100%, train loss 0.1933, valid loss 0.2914, cost 0.2 min\n",
      "[[04/23/2020 18:06:33]] epoch 336 / 1500, batch 100%, train loss 0.1660, valid loss 0.2900, cost 0.2 min\n",
      "[[04/23/2020 18:06:49]] epoch 337 / 1500, batch 100%, train loss 0.2287, valid loss 0.2910, cost 0.3 min\n",
      "[[04/23/2020 18:07:06]] epoch 338 / 1500, batch 100%, train loss 0.2095, valid loss 0.2939, cost 0.3 min\n",
      "[[04/23/2020 18:07:21]] epoch 339 / 1500, batch 100%, train loss 0.0766, valid loss 0.2963, cost 0.2 min\n",
      "[[04/23/2020 18:07:37]] epoch 340 / 1500, batch 100%, train loss 0.0301, valid loss 0.2901, cost 0.3 min\n",
      "[[04/23/2020 18:07:56]] epoch 341 / 1500, batch 100%, train loss 0.1947, valid loss 0.2871, cost 0.3 min\n",
      "[[04/23/2020 18:08:12]] epoch 342 / 1500, batch 100%, train loss 0.0718, valid loss 0.2923, cost 0.3 min\n",
      "[[04/23/2020 18:08:32]] epoch 343 / 1500, batch 100%, train loss 0.2498, valid loss 0.2951, cost 0.3 min\n",
      "[[04/23/2020 18:08:48]] epoch 344 / 1500, batch 100%, train loss 0.0675, valid loss 0.2952, cost 0.3 min\n",
      "[[04/23/2020 18:09:04]] epoch 345 / 1500, batch 100%, train loss 0.2213, valid loss 0.2914, cost 0.3 min\n",
      "[[04/23/2020 18:09:21]] epoch 346 / 1500, batch 100%, train loss 0.1439, valid loss 0.2888, cost 0.3 min\n",
      "[[04/23/2020 18:09:35]] epoch 347 / 1500, batch 100%, train loss 0.1998, valid loss 0.2836, cost 0.2 min\n",
      "[[04/23/2020 18:09:54]] epoch 348 / 1500, batch 100%, train loss 0.1103, valid loss 0.2894, cost 0.3 min\n",
      "[[04/23/2020 18:10:13]] epoch 349 / 1500, batch 100%, train loss 0.2206, valid loss 0.2886, cost 0.3 min\n",
      "[[04/23/2020 18:10:34]] epoch 350 / 1500, batch 100%, train loss 0.2422, valid loss 0.2906, cost 0.3 min\n",
      "[[04/23/2020 18:10:50]] epoch 351 / 1500, batch 100%, train loss 0.1059, valid loss 0.3034, cost 0.3 min\n",
      "[[04/23/2020 18:11:08]] epoch 352 / 1500, batch 100%, train loss 0.1611, valid loss 0.3054, cost 0.3 min\n",
      "[[04/23/2020 18:11:22]] epoch 353 / 1500, batch 100%, train loss 0.0785, valid loss 0.3029, cost 0.2 min\n",
      "[[04/23/2020 18:11:38]] epoch 354 / 1500, batch 100%, train loss 0.1104, valid loss 0.2930, cost 0.3 min\n",
      "[[04/23/2020 18:11:54]] epoch 355 / 1500, batch 100%, train loss 0.3106, valid loss 0.2901, cost 0.3 min\n",
      "[[04/23/2020 18:12:13]] epoch 356 / 1500, batch 100%, train loss 0.1542, valid loss 0.2871, cost 0.3 min\n",
      "[[04/23/2020 18:12:25]] epoch 357 / 1500, batch 100%, train loss 0.1746, valid loss 0.2855, cost 0.2 min\n",
      "[[04/23/2020 18:12:46]] epoch 358 / 1500, batch 100%, train loss 0.1510, valid loss 0.2856, cost 0.3 min\n",
      "[[04/23/2020 18:12:59]] epoch 359 / 1500, batch 100%, train loss 0.1290, valid loss 0.2823, cost 0.2 min\n",
      "[[04/23/2020 18:13:14]] epoch 360 / 1500, batch 100%, train loss 0.1002, valid loss 0.2873, cost 0.3 min\n",
      "[[04/23/2020 18:13:30]] epoch 361 / 1500, batch 100%, train loss 0.2389, valid loss 0.2894, cost 0.3 min\n",
      "[[04/23/2020 18:13:47]] epoch 362 / 1500, batch 100%, train loss 0.3742, valid loss 0.2900, cost 0.3 min\n",
      "[[04/23/2020 18:14:05]] epoch 363 / 1500, batch 100%, train loss 0.1596, valid loss 0.2965, cost 0.3 min\n",
      "[[04/23/2020 18:14:24]] epoch 364 / 1500, batch 100%, train loss 0.1779, valid loss 0.3084, cost 0.3 min\n",
      "[[04/23/2020 18:14:42]] epoch 365 / 1500, batch 100%, train loss 0.9133, valid loss 0.3353, cost 0.3 min\n",
      "[[04/23/2020 18:14:57]] epoch 366 / 1500, batch 100%, train loss 0.2776, valid loss 0.3903, cost 0.2 min\n",
      "[[04/23/2020 18:15:12]] epoch 367 / 1500, batch 100%, train loss 0.1998, valid loss 0.3192, cost 0.3 min\n",
      "[[04/23/2020 18:15:30]] epoch 368 / 1500, batch 100%, train loss 0.1945, valid loss 0.3560, cost 0.3 min\n",
      "[[04/23/2020 18:15:46]] epoch 369 / 1500, batch 100%, train loss 0.2560, valid loss 0.3951, cost 0.3 min\n",
      "[[04/23/2020 18:16:00]] epoch 370 / 1500, batch 100%, train loss 0.1786, valid loss 0.4011, cost 0.2 min\n",
      "[[04/23/2020 18:16:18]] epoch 371 / 1500, batch 100%, train loss 0.3220, valid loss 0.3650, cost 0.3 min\n",
      "[[04/23/2020 18:16:35]] epoch 372 / 1500, batch 100%, train loss 0.1907, valid loss 0.3271, cost 0.3 min\n",
      "[[04/23/2020 18:16:51]] epoch 373 / 1500, batch 100%, train loss 0.2767, valid loss 0.3202, cost 0.3 min\n",
      "[[04/23/2020 18:17:08]] epoch 374 / 1500, batch 100%, train loss 0.1861, valid loss 0.3364, cost 0.3 min\n",
      "[[04/23/2020 18:17:24]] epoch 375 / 1500, batch 100%, train loss 0.1101, valid loss 0.3291, cost 0.3 min\n",
      "[[04/23/2020 18:17:39]] epoch 376 / 1500, batch 100%, train loss 0.0647, valid loss 0.3279, cost 0.3 min\n",
      "[[04/23/2020 18:17:57]] epoch 377 / 1500, batch 100%, train loss 0.4332, valid loss 0.3302, cost 0.3 min\n",
      "[[04/23/2020 18:18:14]] epoch 378 / 1500, batch 100%, train loss 0.4866, valid loss 0.3319, cost 0.3 min\n",
      "[[04/23/2020 18:18:31]] epoch 379 / 1500, batch 100%, train loss 0.4070, valid loss 0.3308, cost 0.3 min\n",
      "[[04/23/2020 18:18:46]] epoch 380 / 1500, batch 100%, train loss 0.3163, valid loss 0.3061, cost 0.2 min\n",
      "[[04/23/2020 18:19:01]] epoch 381 / 1500, batch 100%, train loss 0.1726, valid loss 0.3098, cost 0.3 min\n",
      "[[04/23/2020 18:19:18]] epoch 382 / 1500, batch 100%, train loss 0.1038, valid loss 0.3054, cost 0.3 min\n",
      "[[04/23/2020 18:19:38]] epoch 383 / 1500, batch 100%, train loss 0.5747, valid loss 0.3302, cost 0.3 min\n",
      "[[04/23/2020 18:19:53]] epoch 384 / 1500, batch 100%, train loss 0.8977, valid loss 0.3462, cost 0.3 min\n",
      "[[04/23/2020 18:20:15]] epoch 385 / 1500, batch 100%, train loss 0.4783, valid loss 0.2971, cost 0.4 min\n",
      "[[04/23/2020 18:20:32]] epoch 386 / 1500, batch 100%, train loss 0.1570, valid loss 0.3143, cost 0.3 min\n",
      "[[04/23/2020 18:20:50]] epoch 387 / 1500, batch 100%, train loss 0.1577, valid loss 0.3295, cost 0.3 min\n",
      "[[04/23/2020 18:21:02]] epoch 388 / 1500, batch 100%, train loss 0.4769, valid loss 0.3089, cost 0.2 min\n",
      "[[04/23/2020 18:21:19]] epoch 389 / 1500, batch 100%, train loss 0.0547, valid loss 0.3965, cost 0.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 18:21:36]] epoch 390 / 1500, batch 100%, train loss 0.1338, valid loss 0.4373, cost 0.3 min\n",
      "[[04/23/2020 18:21:58]] epoch 391 / 1500, batch 100%, train loss 0.4019, valid loss 0.4143, cost 0.4 min\n",
      "[[04/23/2020 18:22:11]] epoch 392 / 1500, batch 100%, train loss 0.2736, valid loss 0.3553, cost 0.2 min\n",
      "[[04/23/2020 18:22:31]] epoch 393 / 1500, batch 100%, train loss 0.2192, valid loss 0.3123, cost 0.3 min\n",
      "[[04/23/2020 18:22:48]] epoch 394 / 1500, batch 100%, train loss 0.0811, valid loss 0.2953, cost 0.3 min\n",
      "[[04/23/2020 18:23:05]] epoch 395 / 1500, batch 100%, train loss 0.0790, valid loss 0.2886, cost 0.3 min\n",
      "[[04/23/2020 18:23:26]] epoch 396 / 1500, batch 100%, train loss 0.2481, valid loss 0.2859, cost 0.3 min\n",
      "[[04/23/2020 18:23:45]] epoch 397 / 1500, batch 100%, train loss 0.1130, valid loss 0.2877, cost 0.3 min\n",
      "[[04/23/2020 18:24:04]] epoch 398 / 1500, batch 100%, train loss 0.3477, valid loss 0.2846, cost 0.3 min\n",
      "[[04/23/2020 18:24:26]] epoch 399 / 1500, batch 100%, train loss 0.2458, valid loss 0.2997, cost 0.4 min\n",
      "[[04/23/2020 18:24:41]] epoch 400 / 1500, batch 100%, train loss 0.1161, valid loss 0.3177, cost 0.2 min\n",
      "[[04/23/2020 18:24:55]] epoch 401 / 1500, batch 100%, train loss 0.1832, valid loss 0.3246, cost 0.2 min\n",
      "[[04/23/2020 18:25:11]] epoch 402 / 1500, batch 100%, train loss 0.1912, valid loss 0.3095, cost 0.3 min\n",
      "[[04/23/2020 18:25:27]] epoch 403 / 1500, batch 100%, train loss 0.1002, valid loss 0.3093, cost 0.3 min\n",
      "[[04/23/2020 18:25:42]] epoch 404 / 1500, batch 100%, train loss 0.1018, valid loss 0.3111, cost 0.2 min\n",
      "[[04/23/2020 18:25:58]] epoch 405 / 1500, batch 100%, train loss 0.3023, valid loss 0.3139, cost 0.3 min\n",
      "[[04/23/2020 18:26:11]] epoch 406 / 1500, batch 100%, train loss 0.1701, valid loss 0.3079, cost 0.2 min\n",
      "[[04/23/2020 18:26:26]] epoch 407 / 1500, batch 100%, train loss 0.4152, valid loss 0.3022, cost 0.3 min\n",
      "[[04/23/2020 18:26:45]] epoch 408 / 1500, batch 100%, train loss 0.3230, valid loss 0.3024, cost 0.3 min\n",
      "[[04/23/2020 18:26:59]] epoch 409 / 1500, batch 100%, train loss 0.0618, valid loss 0.3021, cost 0.2 min\n",
      "[[04/23/2020 18:27:14]] epoch 410 / 1500, batch 100%, train loss 0.0880, valid loss 0.3035, cost 0.2 min\n",
      "[[04/23/2020 18:27:29]] epoch 411 / 1500, batch 100%, train loss 0.5050, valid loss 0.2936, cost 0.3 min\n",
      "[[04/23/2020 18:27:43]] epoch 412 / 1500, batch 100%, train loss 0.2332, valid loss 0.2996, cost 0.2 min\n",
      "[[04/23/2020 18:28:01]] epoch 413 / 1500, batch 100%, train loss 0.0905, valid loss 0.3098, cost 0.3 min\n",
      "[[04/23/2020 18:28:20]] epoch 414 / 1500, batch 100%, train loss 0.0962, valid loss 0.3156, cost 0.3 min\n",
      "[[04/23/2020 18:28:38]] epoch 415 / 1500, batch 100%, train loss 0.2090, valid loss 0.3127, cost 0.3 min\n",
      "[[04/23/2020 18:28:55]] epoch 416 / 1500, batch 100%, train loss 0.0660, valid loss 0.3115, cost 0.3 min\n",
      "[[04/23/2020 18:29:11]] epoch 417 / 1500, batch 100%, train loss 0.1394, valid loss 0.3074, cost 0.3 min\n",
      "[[04/23/2020 18:29:28]] epoch 418 / 1500, batch 100%, train loss 0.1012, valid loss 0.3062, cost 0.3 min\n",
      "[[04/23/2020 18:29:47]] epoch 419 / 1500, batch 100%, train loss 0.4027, valid loss 0.2939, cost 0.3 min\n",
      "[[04/23/2020 18:30:00]] epoch 420 / 1500, batch 100%, train loss 0.1959, valid loss 0.2881, cost 0.2 min\n",
      "[[04/23/2020 18:30:14]] epoch 421 / 1500, batch 100%, train loss 0.1894, valid loss 0.2896, cost 0.2 min\n",
      "[[04/23/2020 18:30:34]] epoch 422 / 1500, batch 100%, train loss 0.0934, valid loss 0.2834, cost 0.3 min\n",
      "[[04/23/2020 18:30:52]] epoch 423 / 1500, batch 100%, train loss 0.2224, valid loss 0.2880, cost 0.3 min\n",
      "[[04/23/2020 18:31:12]] epoch 424 / 1500, batch 100%, train loss 0.1708, valid loss 0.2855, cost 0.3 min\n",
      "[[04/23/2020 18:31:30]] epoch 425 / 1500, batch 100%, train loss 0.1030, valid loss 0.2845, cost 0.3 min\n",
      "[[04/23/2020 18:31:47]] epoch 426 / 1500, batch 100%, train loss 0.5380, valid loss 0.2817, cost 0.3 min\n",
      "[[04/23/2020 18:32:03]] epoch 427 / 1500, batch 100%, train loss 0.0835, valid loss 0.2891, cost 0.3 min\n",
      "[[04/23/2020 18:32:20]] epoch 428 / 1500, batch 100%, train loss 0.1543, valid loss 0.2895, cost 0.3 min\n",
      "[[04/23/2020 18:32:37]] epoch 429 / 1500, batch 100%, train loss 0.0523, valid loss 0.2857, cost 0.3 min\n",
      "[[04/23/2020 18:32:55]] epoch 430 / 1500, batch 100%, train loss 0.4560, valid loss 0.2907, cost 0.3 min\n",
      "[[04/23/2020 18:33:15]] epoch 431 / 1500, batch 100%, train loss 0.1839, valid loss 0.2939, cost 0.3 min\n",
      "[[04/23/2020 18:33:32]] epoch 432 / 1500, batch 100%, train loss 0.5377, valid loss 0.2917, cost 0.3 min\n",
      "[[04/23/2020 18:33:49]] epoch 433 / 1500, batch 100%, train loss 0.3218, valid loss 0.2890, cost 0.3 min\n",
      "[[04/23/2020 18:34:05]] epoch 434 / 1500, batch 100%, train loss 0.0867, valid loss 0.2829, cost 0.3 min\n",
      "[[04/23/2020 18:34:21]] epoch 435 / 1500, batch 100%, train loss 0.2068, valid loss 0.2794, cost 0.3 min\n",
      "[[04/23/2020 18:34:40]] epoch 436 / 1500, batch 100%, train loss 0.1172, valid loss 0.2870, cost 0.3 min\n",
      "[[04/23/2020 18:34:55]] epoch 437 / 1500, batch 100%, train loss 0.2801, valid loss 0.2846, cost 0.3 min\n",
      "[[04/23/2020 18:35:11]] epoch 438 / 1500, batch 100%, train loss 0.0963, valid loss 0.2848, cost 0.3 min\n",
      "[[04/23/2020 18:35:27]] epoch 439 / 1500, batch 100%, train loss 0.1660, valid loss 0.2843, cost 0.3 min\n",
      "[[04/23/2020 18:35:42]] epoch 440 / 1500, batch 100%, train loss 0.1396, valid loss 0.2876, cost 0.2 min\n",
      "[[04/23/2020 18:35:56]] epoch 441 / 1500, batch 100%, train loss 0.5639, valid loss 0.2900, cost 0.2 min\n",
      "[[04/23/2020 18:36:13]] epoch 442 / 1500, batch 100%, train loss 0.1198, valid loss 0.2827, cost 0.3 min\n",
      "[[04/23/2020 18:36:30]] epoch 443 / 1500, batch 100%, train loss 0.1413, valid loss 0.2860, cost 0.3 min\n",
      "[[04/23/2020 18:36:46]] epoch 444 / 1500, batch 100%, train loss 0.0647, valid loss 0.2810, cost 0.3 min\n",
      "[[04/23/2020 18:37:00]] epoch 445 / 1500, batch 100%, train loss 0.2384, valid loss 0.2824, cost 0.2 min\n",
      "[[04/23/2020 18:37:18]] epoch 446 / 1500, batch 100%, train loss 0.0583, valid loss 0.2857, cost 0.3 min\n",
      "[[04/23/2020 18:37:34]] epoch 447 / 1500, batch 100%, train loss 0.2668, valid loss 0.2840, cost 0.3 min\n",
      "[[04/23/2020 18:37:49]] epoch 448 / 1500, batch 100%, train loss 0.2817, valid loss 0.2873, cost 0.3 min\n",
      "[[04/23/2020 18:38:08]] epoch 449 / 1500, batch 100%, train loss 0.1152, valid loss 0.2845, cost 0.3 min\n",
      "[[04/23/2020 18:38:23]] epoch 450 / 1500, batch 100%, train loss 0.1543, valid loss 0.2836, cost 0.3 min\n",
      "[[04/23/2020 18:38:41]] epoch 451 / 1500, batch 100%, train loss 0.1538, valid loss 0.2858, cost 0.3 min\n",
      "[[04/23/2020 18:39:00]] epoch 452 / 1500, batch 100%, train loss 0.2259, valid loss 0.2909, cost 0.3 min\n",
      "[[04/23/2020 18:39:20]] epoch 453 / 1500, batch 100%, train loss 0.1828, valid loss 0.2933, cost 0.3 min\n",
      "[[04/23/2020 18:39:34]] epoch 454 / 1500, batch 100%, train loss 0.2738, valid loss 0.2912, cost 0.2 min\n",
      "[[04/23/2020 18:39:53]] epoch 455 / 1500, batch 100%, train loss 0.2893, valid loss 0.2849, cost 0.3 min\n",
      "[[04/23/2020 18:40:11]] epoch 456 / 1500, batch 100%, train loss 0.0945, valid loss 0.2865, cost 0.3 min\n",
      "[[04/23/2020 18:40:29]] epoch 457 / 1500, batch 100%, train loss 0.1752, valid loss 0.2912, cost 0.3 min\n",
      "[[04/23/2020 18:40:46]] epoch 458 / 1500, batch 100%, train loss 0.1352, valid loss 0.2908, cost 0.3 min\n",
      "[[04/23/2020 18:41:00]] epoch 459 / 1500, batch 100%, train loss 0.1503, valid loss 0.2880, cost 0.2 min\n",
      "[[04/23/2020 18:41:17]] epoch 460 / 1500, batch 100%, train loss 0.1359, valid loss 0.2901, cost 0.3 min\n",
      "[[04/23/2020 18:41:34]] epoch 461 / 1500, batch 100%, train loss 0.1670, valid loss 0.2893, cost 0.3 min\n",
      "[[04/23/2020 18:41:50]] epoch 462 / 1500, batch 100%, train loss 0.1493, valid loss 0.2930, cost 0.3 min\n",
      "[[04/23/2020 18:42:12]] epoch 463 / 1500, batch 100%, train loss 0.7948, valid loss 0.2876, cost 0.4 min\n",
      "[[04/23/2020 18:42:27]] epoch 464 / 1500, batch 100%, train loss 0.0363, valid loss 0.2849, cost 0.3 min\n",
      "[[04/23/2020 18:42:46]] epoch 465 / 1500, batch 100%, train loss 0.2854, valid loss 0.2811, cost 0.3 min\n",
      "[[04/23/2020 18:43:07]] epoch 466 / 1500, batch 100%, train loss 0.0803, valid loss 0.2783, cost 0.3 min\n",
      "[[04/23/2020 18:43:23]] epoch 467 / 1500, batch 100%, train loss 0.1514, valid loss 0.2821, cost 0.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 18:43:43]] epoch 468 / 1500, batch 100%, train loss 0.0785, valid loss 0.2832, cost 0.3 min\n",
      "[[04/23/2020 18:43:57]] epoch 469 / 1500, batch 100%, train loss 0.0342, valid loss 0.2775, cost 0.2 min\n",
      "[[04/23/2020 18:44:16]] epoch 470 / 1500, batch 100%, train loss 0.0810, valid loss 0.2804, cost 0.3 min\n",
      "[[04/23/2020 18:44:33]] epoch 471 / 1500, batch 100%, train loss 0.2057, valid loss 0.2796, cost 0.3 min\n",
      "[[04/23/2020 18:44:53]] epoch 472 / 1500, batch 100%, train loss 0.6085, valid loss 0.2791, cost 0.3 min\n",
      "[[04/23/2020 18:45:10]] epoch 473 / 1500, batch 100%, train loss 0.2453, valid loss 0.2854, cost 0.3 min\n",
      "[[04/23/2020 18:45:28]] epoch 474 / 1500, batch 100%, train loss 0.0592, valid loss 0.2843, cost 0.3 min\n",
      "[[04/23/2020 18:45:44]] epoch 475 / 1500, batch 100%, train loss 0.0958, valid loss 0.2840, cost 0.3 min\n",
      "[[04/23/2020 18:46:00]] epoch 476 / 1500, batch 100%, train loss 0.2446, valid loss 0.2849, cost 0.3 min\n",
      "[[04/23/2020 18:46:15]] epoch 477 / 1500, batch 100%, train loss 0.0486, valid loss 0.2853, cost 0.3 min\n",
      "[[04/23/2020 18:46:37]] epoch 478 / 1500, batch 100%, train loss 0.1985, valid loss 0.2806, cost 0.4 min\n",
      "[[04/23/2020 18:46:52]] epoch 479 / 1500, batch 100%, train loss 0.1819, valid loss 0.2811, cost 0.2 min\n",
      "[[04/23/2020 18:47:07]] epoch 480 / 1500, batch 100%, train loss 0.5633, valid loss 0.2918, cost 0.3 min\n",
      "[[04/23/2020 18:47:27]] epoch 481 / 1500, batch 100%, train loss 0.1001, valid loss 0.2996, cost 0.3 min\n",
      "[[04/23/2020 18:47:45]] epoch 482 / 1500, batch 100%, train loss 0.2448, valid loss 0.2955, cost 0.3 min\n",
      "[[04/23/2020 18:48:05]] epoch 483 / 1500, batch 100%, train loss 0.1263, valid loss 0.2898, cost 0.3 min\n",
      "[[04/23/2020 18:48:23]] epoch 484 / 1500, batch 100%, train loss 0.2553, valid loss 0.2785, cost 0.3 min\n",
      "[[04/23/2020 18:48:39]] epoch 485 / 1500, batch 100%, train loss 0.1369, valid loss 0.2759, cost 0.3 min\n",
      "[[04/23/2020 18:48:57]] epoch 486 / 1500, batch 100%, train loss 0.0636, valid loss 0.2729, cost 0.3 min\n",
      "[[04/23/2020 18:49:15]] epoch 487 / 1500, batch 100%, train loss 0.1192, valid loss 0.2790, cost 0.3 min\n",
      "[[04/23/2020 18:49:34]] epoch 488 / 1500, batch 100%, train loss 0.3853, valid loss 0.2846, cost 0.3 min\n",
      "[[04/23/2020 18:49:53]] epoch 489 / 1500, batch 100%, train loss 0.1112, valid loss 0.2834, cost 0.3 min\n",
      "[[04/23/2020 18:50:12]] epoch 490 / 1500, batch 100%, train loss 0.0958, valid loss 0.2794, cost 0.3 min\n",
      "[[04/23/2020 18:50:27]] epoch 491 / 1500, batch 100%, train loss 0.0346, valid loss 0.2791, cost 0.3 min\n",
      "[[04/23/2020 18:50:41]] epoch 492 / 1500, batch 100%, train loss 0.5725, valid loss 0.2862, cost 0.2 min\n",
      "[[04/23/2020 18:50:56]] epoch 493 / 1500, batch 100%, train loss 0.1091, valid loss 0.2838, cost 0.2 min\n",
      "[[04/23/2020 18:51:13]] epoch 494 / 1500, batch 100%, train loss 0.1498, valid loss 0.2915, cost 0.3 min\n",
      "[[04/23/2020 18:51:36]] epoch 495 / 1500, batch 100%, train loss 0.1257, valid loss 0.2854, cost 0.4 min\n",
      "[[04/23/2020 18:51:50]] epoch 496 / 1500, batch 100%, train loss 0.0804, valid loss 0.2912, cost 0.2 min\n",
      "[[04/23/2020 18:52:06]] epoch 497 / 1500, batch 100%, train loss 0.0434, valid loss 0.2872, cost 0.3 min\n",
      "[[04/23/2020 18:52:24]] epoch 498 / 1500, batch 100%, train loss 0.2391, valid loss 0.2902, cost 0.3 min\n",
      "[[04/23/2020 18:52:38]] epoch 499 / 1500, batch 100%, train loss 0.4807, valid loss 0.3154, cost 0.2 min\n",
      "[[04/23/2020 18:52:59]] epoch 500 / 1500, batch 100%, train loss 0.4666, valid loss 0.3138, cost 0.3 min\n",
      "[[04/23/2020 18:53:15]] epoch 501 / 1500, batch 100%, train loss 0.0439, valid loss 0.3004, cost 0.3 min\n",
      "[[04/23/2020 18:53:31]] epoch 502 / 1500, batch 100%, train loss 0.3314, valid loss 0.2957, cost 0.3 min\n",
      "[[04/23/2020 18:53:48]] epoch 503 / 1500, batch 100%, train loss 0.2640, valid loss 0.2972, cost 0.3 min\n",
      "[[04/23/2020 18:54:06]] epoch 504 / 1500, batch 100%, train loss 0.0971, valid loss 0.2824, cost 0.3 min\n",
      "[[04/23/2020 18:54:24]] epoch 505 / 1500, batch 100%, train loss 0.6456, valid loss 0.2885, cost 0.3 min\n",
      "[[04/23/2020 18:54:43]] epoch 506 / 1500, batch 100%, train loss 0.2305, valid loss 0.3026, cost 0.3 min\n",
      "[[04/23/2020 18:55:02]] epoch 507 / 1500, batch 100%, train loss 0.4339, valid loss 0.3082, cost 0.3 min\n",
      "[[04/23/2020 18:55:18]] epoch 508 / 1500, batch 100%, train loss 0.2052, valid loss 0.3048, cost 0.3 min\n",
      "[[04/23/2020 18:55:35]] epoch 509 / 1500, batch 100%, train loss 0.3115, valid loss 0.2848, cost 0.3 min\n",
      "[[04/23/2020 18:55:54]] epoch 510 / 1500, batch 100%, train loss 0.1502, valid loss 0.2850, cost 0.3 min\n",
      "[[04/23/2020 18:56:08]] epoch 511 / 1500, batch 100%, train loss 0.0923, valid loss 0.2894, cost 0.2 min\n",
      "[[04/23/2020 18:56:30]] epoch 512 / 1500, batch 100%, train loss 0.1470, valid loss 0.2964, cost 0.4 min\n",
      "[[04/23/2020 18:56:46]] epoch 513 / 1500, batch 100%, train loss 0.1007, valid loss 0.2848, cost 0.3 min\n",
      "[[04/23/2020 18:57:02]] epoch 514 / 1500, batch 100%, train loss 0.2932, valid loss 0.2884, cost 0.3 min\n",
      "[[04/23/2020 18:57:19]] epoch 515 / 1500, batch 100%, train loss 0.2031, valid loss 0.2942, cost 0.3 min\n",
      "[[04/23/2020 18:57:38]] epoch 516 / 1500, batch 100%, train loss 0.2907, valid loss 0.2819, cost 0.3 min\n",
      "[[04/23/2020 18:57:53]] epoch 517 / 1500, batch 100%, train loss 0.2869, valid loss 0.2758, cost 0.3 min\n",
      "[[04/23/2020 18:58:15]] epoch 518 / 1500, batch 100%, train loss 0.1855, valid loss 0.2758, cost 0.4 min\n",
      "[[04/23/2020 18:58:36]] epoch 519 / 1500, batch 100%, train loss 0.1658, valid loss 0.2771, cost 0.4 min\n",
      "[[04/23/2020 18:58:55]] epoch 520 / 1500, batch 100%, train loss 0.3569, valid loss 0.2825, cost 0.3 min\n",
      "[[04/23/2020 18:59:12]] epoch 521 / 1500, batch 100%, train loss 0.7214, valid loss 0.3073, cost 0.3 min\n",
      "[[04/23/2020 18:59:29]] epoch 522 / 1500, batch 100%, train loss 0.1663, valid loss 0.3177, cost 0.3 min\n",
      "[[04/23/2020 18:59:45]] epoch 523 / 1500, batch 100%, train loss 0.3117, valid loss 0.2996, cost 0.3 min\n",
      "[[04/23/2020 19:00:03]] epoch 524 / 1500, batch 100%, train loss 0.0515, valid loss 0.2899, cost 0.3 min\n",
      "[[04/23/2020 19:00:23]] epoch 525 / 1500, batch 100%, train loss 0.2151, valid loss 0.2808, cost 0.3 min\n",
      "[[04/23/2020 19:00:42]] epoch 526 / 1500, batch 100%, train loss 0.2392, valid loss 0.2704, cost 0.3 min\n",
      "[[04/23/2020 19:01:00]] epoch 527 / 1500, batch 100%, train loss 0.0254, valid loss 0.2659, cost 0.3 min\n",
      "[[04/23/2020 19:01:17]] epoch 528 / 1500, batch 100%, train loss 0.2058, valid loss 0.2705, cost 0.3 min\n",
      "[[04/23/2020 19:01:34]] epoch 529 / 1500, batch 100%, train loss 0.0519, valid loss 0.2787, cost 0.3 min\n",
      "[[04/23/2020 19:01:50]] epoch 530 / 1500, batch 100%, train loss 0.2693, valid loss 0.2721, cost 0.3 min\n",
      "[[04/23/2020 19:02:07]] epoch 531 / 1500, batch 100%, train loss 0.2054, valid loss 0.2801, cost 0.3 min\n",
      "[[04/23/2020 19:02:23]] epoch 532 / 1500, batch 100%, train loss 0.0619, valid loss 0.2868, cost 0.3 min\n",
      "[[04/23/2020 19:02:43]] epoch 533 / 1500, batch 100%, train loss 0.0532, valid loss 0.2828, cost 0.3 min\n",
      "[[04/23/2020 19:03:00]] epoch 534 / 1500, batch 100%, train loss 0.0745, valid loss 0.2815, cost 0.3 min\n",
      "[[04/23/2020 19:03:19]] epoch 535 / 1500, batch 100%, train loss 0.1545, valid loss 0.2772, cost 0.3 min\n",
      "[[04/23/2020 19:03:39]] epoch 536 / 1500, batch 100%, train loss 0.1912, valid loss 0.2771, cost 0.3 min\n",
      "[[04/23/2020 19:03:56]] epoch 537 / 1500, batch 100%, train loss 0.1504, valid loss 0.2706, cost 0.3 min\n",
      "[[04/23/2020 19:04:19]] epoch 538 / 1500, batch 100%, train loss 0.0983, valid loss 0.2710, cost 0.4 min\n",
      "[[04/23/2020 19:04:36]] epoch 539 / 1500, batch 100%, train loss 0.2655, valid loss 0.2749, cost 0.3 min\n",
      "[[04/23/2020 19:04:57]] epoch 540 / 1500, batch 100%, train loss 0.0912, valid loss 0.2791, cost 0.3 min\n",
      "[[04/23/2020 19:05:18]] epoch 541 / 1500, batch 100%, train loss 0.0540, valid loss 0.2809, cost 0.4 min\n",
      "[[04/23/2020 19:05:31]] epoch 542 / 1500, batch 100%, train loss 0.3557, valid loss 0.2932, cost 0.2 min\n",
      "[[04/23/2020 19:05:44]] epoch 543 / 1500, batch 100%, train loss 0.1618, valid loss 0.3009, cost 0.2 min\n",
      "[[04/23/2020 19:05:59]] epoch 544 / 1500, batch 100%, train loss 0.3449, valid loss 0.2833, cost 0.2 min\n",
      "[[04/23/2020 19:06:17]] epoch 545 / 1500, batch 100%, train loss 0.1973, valid loss 0.2798, cost 0.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 19:06:33]] epoch 546 / 1500, batch 100%, train loss 0.0951, valid loss 0.2795, cost 0.3 min\n",
      "[[04/23/2020 19:06:53]] epoch 547 / 1500, batch 100%, train loss 0.3571, valid loss 0.2842, cost 0.3 min\n",
      "[[04/23/2020 19:07:08]] epoch 548 / 1500, batch 100%, train loss 0.1058, valid loss 0.2870, cost 0.3 min\n",
      "[[04/23/2020 19:07:30]] epoch 549 / 1500, batch 100%, train loss 0.1060, valid loss 0.2904, cost 0.4 min\n",
      "[[04/23/2020 19:07:43]] epoch 550 / 1500, batch 100%, train loss 0.3442, valid loss 0.3025, cost 0.2 min\n",
      "[[04/23/2020 19:07:59]] epoch 551 / 1500, batch 100%, train loss 0.1805, valid loss 0.3048, cost 0.3 min\n",
      "[[04/23/2020 19:08:19]] epoch 552 / 1500, batch 100%, train loss 0.1161, valid loss 0.3005, cost 0.3 min\n",
      "[[04/23/2020 19:08:35]] epoch 553 / 1500, batch 100%, train loss 0.2549, valid loss 0.3019, cost 0.3 min\n",
      "[[04/23/2020 19:08:52]] epoch 554 / 1500, batch 100%, train loss 0.2317, valid loss 0.2962, cost 0.3 min\n",
      "[[04/23/2020 19:09:10]] epoch 555 / 1500, batch 100%, train loss 0.2687, valid loss 0.2937, cost 0.3 min\n",
      "[[04/23/2020 19:09:26]] epoch 556 / 1500, batch 100%, train loss 0.0784, valid loss 0.2896, cost 0.3 min\n",
      "[[04/23/2020 19:09:43]] epoch 557 / 1500, batch 100%, train loss 0.0828, valid loss 0.2913, cost 0.3 min\n",
      "[[04/23/2020 19:09:59]] epoch 558 / 1500, batch 100%, train loss 0.1462, valid loss 0.2803, cost 0.3 min\n",
      "[[04/23/2020 19:10:15]] epoch 559 / 1500, batch 100%, train loss 0.0614, valid loss 0.2808, cost 0.3 min\n",
      "[[04/23/2020 19:10:30]] epoch 560 / 1500, batch 100%, train loss 0.2418, valid loss 0.2779, cost 0.3 min\n",
      "[[04/23/2020 19:10:50]] epoch 561 / 1500, batch 100%, train loss 0.1874, valid loss 0.2709, cost 0.3 min\n",
      "[[04/23/2020 19:11:10]] epoch 562 / 1500, batch 100%, train loss 0.0642, valid loss 0.2730, cost 0.3 min\n",
      "[[04/23/2020 19:11:27]] epoch 563 / 1500, batch 100%, train loss 0.2775, valid loss 0.2686, cost 0.3 min\n",
      "[[04/23/2020 19:11:47]] epoch 564 / 1500, batch 100%, train loss 0.2479, valid loss 0.2677, cost 0.3 min\n",
      "[[04/23/2020 19:12:03]] epoch 565 / 1500, batch 100%, train loss 0.2432, valid loss 0.2725, cost 0.3 min\n",
      "[[04/23/2020 19:12:20]] epoch 566 / 1500, batch 100%, train loss 0.0839, valid loss 0.2691, cost 0.3 min\n",
      "[[04/23/2020 19:12:36]] epoch 567 / 1500, batch 100%, train loss 0.1692, valid loss 0.2669, cost 0.3 min\n",
      "[[04/23/2020 19:12:54]] epoch 568 / 1500, batch 100%, train loss 0.1441, valid loss 0.2689, cost 0.3 min\n",
      "[[04/23/2020 19:13:10]] epoch 569 / 1500, batch 100%, train loss 0.3224, valid loss 0.2680, cost 0.3 min\n",
      "[[04/23/2020 19:13:30]] epoch 570 / 1500, batch 100%, train loss 0.1233, valid loss 0.2674, cost 0.3 min\n",
      "[[04/23/2020 19:13:48]] epoch 571 / 1500, batch 100%, train loss 0.1709, valid loss 0.2716, cost 0.3 min\n",
      "[[04/23/2020 19:14:05]] epoch 572 / 1500, batch 100%, train loss 0.2571, valid loss 0.2666, cost 0.3 min\n",
      "[[04/23/2020 19:14:21]] epoch 573 / 1500, batch 100%, train loss 0.0584, valid loss 0.2653, cost 0.3 min\n",
      "[[04/23/2020 19:14:38]] epoch 574 / 1500, batch 100%, train loss 0.0978, valid loss 0.2690, cost 0.3 min\n",
      "[[04/23/2020 19:14:58]] epoch 575 / 1500, batch 100%, train loss 0.2855, valid loss 0.2665, cost 0.3 min\n",
      "[[04/23/2020 19:15:12]] epoch 576 / 1500, batch 100%, train loss 0.1173, valid loss 0.2682, cost 0.2 min\n",
      "[[04/23/2020 19:15:33]] epoch 577 / 1500, batch 100%, train loss 0.2137, valid loss 0.2628, cost 0.4 min\n",
      "[[04/23/2020 19:15:51]] epoch 578 / 1500, batch 100%, train loss 0.2498, valid loss 0.2677, cost 0.3 min\n",
      "[[04/23/2020 19:16:06]] epoch 579 / 1500, batch 100%, train loss 0.1006, valid loss 0.2686, cost 0.3 min\n",
      "[[04/23/2020 19:16:25]] epoch 580 / 1500, batch 100%, train loss 0.1389, valid loss 0.2685, cost 0.3 min\n",
      "[[04/23/2020 19:16:40]] epoch 581 / 1500, batch 100%, train loss 0.3364, valid loss 0.2727, cost 0.3 min\n",
      "[[04/23/2020 19:16:59]] epoch 582 / 1500, batch 100%, train loss 0.2977, valid loss 0.2683, cost 0.3 min\n",
      "[[04/23/2020 19:17:19]] epoch 583 / 1500, batch 100%, train loss 0.2338, valid loss 0.2742, cost 0.3 min\n",
      "[[04/23/2020 19:17:36]] epoch 584 / 1500, batch 100%, train loss 0.2645, valid loss 0.2668, cost 0.3 min\n",
      "[[04/23/2020 19:17:50]] epoch 585 / 1500, batch 100%, train loss 0.0915, valid loss 0.2708, cost 0.2 min\n",
      "[[04/23/2020 19:18:08]] epoch 586 / 1500, batch 100%, train loss 0.1805, valid loss 0.2690, cost 0.3 min\n",
      "[[04/23/2020 19:18:27]] epoch 587 / 1500, batch 100%, train loss 0.1057, valid loss 0.2661, cost 0.3 min\n",
      "[[04/23/2020 19:18:45]] epoch 588 / 1500, batch 100%, train loss 0.2948, valid loss 0.2744, cost 0.3 min\n",
      "[[04/23/2020 19:19:02]] epoch 589 / 1500, batch 100%, train loss 0.1659, valid loss 0.2669, cost 0.3 min\n",
      "[[04/23/2020 19:19:22]] epoch 590 / 1500, batch 100%, train loss 0.1270, valid loss 0.2759, cost 0.3 min\n",
      "[[04/23/2020 19:19:37]] epoch 591 / 1500, batch 100%, train loss 0.0582, valid loss 0.2741, cost 0.3 min\n",
      "[[04/23/2020 19:19:56]] epoch 592 / 1500, batch 100%, train loss 0.1294, valid loss 0.2759, cost 0.3 min\n",
      "[[04/23/2020 19:20:14]] epoch 593 / 1500, batch 100%, train loss 0.1955, valid loss 0.2772, cost 0.3 min\n",
      "[[04/23/2020 19:20:32]] epoch 594 / 1500, batch 100%, train loss 0.2696, valid loss 0.2763, cost 0.3 min\n",
      "[[04/23/2020 19:20:47]] epoch 595 / 1500, batch 100%, train loss 0.1417, valid loss 0.2734, cost 0.2 min\n",
      "[[04/23/2020 19:21:03]] epoch 596 / 1500, batch 100%, train loss 0.4491, valid loss 0.2724, cost 0.3 min\n",
      "[[04/23/2020 19:21:19]] epoch 597 / 1500, batch 100%, train loss 0.9590, valid loss 0.2703, cost 0.3 min\n",
      "[[04/23/2020 19:21:36]] epoch 598 / 1500, batch 100%, train loss 0.0695, valid loss 0.2708, cost 0.3 min\n",
      "[[04/23/2020 19:21:52]] epoch 599 / 1500, batch 100%, train loss 0.1461, valid loss 0.2718, cost 0.3 min\n",
      "[[04/23/2020 19:22:07]] epoch 600 / 1500, batch 100%, train loss 0.0800, valid loss 0.2726, cost 0.2 min\n",
      "[[04/23/2020 19:22:24]] epoch 601 / 1500, batch 100%, train loss 0.2546, valid loss 0.2705, cost 0.3 min\n",
      "[[04/23/2020 19:22:44]] epoch 602 / 1500, batch 100%, train loss 0.2719, valid loss 0.2731, cost 0.3 min\n",
      "[[04/23/2020 19:22:59]] epoch 603 / 1500, batch 100%, train loss 0.2850, valid loss 0.2743, cost 0.3 min\n",
      "[[04/23/2020 19:23:13]] epoch 604 / 1500, batch 100%, train loss 0.5210, valid loss 0.2698, cost 0.2 min\n",
      "[[04/23/2020 19:23:28]] epoch 605 / 1500, batch 100%, train loss 0.4459, valid loss 0.2785, cost 0.3 min\n",
      "[[04/23/2020 19:23:48]] epoch 606 / 1500, batch 100%, train loss 0.5978, valid loss 0.2758, cost 0.3 min\n",
      "[[04/23/2020 19:24:03]] epoch 607 / 1500, batch 100%, train loss 0.7478, valid loss 0.2756, cost 0.3 min\n",
      "[[04/23/2020 19:24:19]] epoch 608 / 1500, batch 100%, train loss 0.0701, valid loss 0.2763, cost 0.3 min\n",
      "[[04/23/2020 19:24:34]] epoch 609 / 1500, batch 100%, train loss 0.3512, valid loss 0.2788, cost 0.2 min\n",
      "[[04/23/2020 19:24:49]] epoch 610 / 1500, batch 100%, train loss 0.1576, valid loss 0.2803, cost 0.2 min\n",
      "[[04/23/2020 19:25:07]] epoch 611 / 1500, batch 100%, train loss 0.5310, valid loss 0.2798, cost 0.3 min\n",
      "[[04/23/2020 19:25:25]] epoch 612 / 1500, batch 100%, train loss 0.0622, valid loss 0.2922, cost 0.3 min\n",
      "[[04/23/2020 19:25:45]] epoch 613 / 1500, batch 100%, train loss 0.1589, valid loss 0.3150, cost 0.3 min\n",
      "[[04/23/2020 19:26:01]] epoch 614 / 1500, batch 100%, train loss 0.0605, valid loss 0.3274, cost 0.3 min\n",
      "[[04/23/2020 19:26:14]] epoch 615 / 1500, batch 100%, train loss 0.5659, valid loss 0.2920, cost 0.2 min\n",
      "[[04/23/2020 19:26:30]] epoch 616 / 1500, batch 100%, train loss 0.1135, valid loss 0.2873, cost 0.3 min\n",
      "[[04/23/2020 19:26:47]] epoch 617 / 1500, batch 100%, train loss 0.3166, valid loss 0.2941, cost 0.3 min\n",
      "[[04/23/2020 19:27:03]] epoch 618 / 1500, batch 100%, train loss 0.1361, valid loss 0.2947, cost 0.3 min\n",
      "[[04/23/2020 19:27:23]] epoch 619 / 1500, batch 100%, train loss 0.0499, valid loss 0.2972, cost 0.3 min\n",
      "[[04/23/2020 19:27:36]] epoch 620 / 1500, batch 100%, train loss 0.2540, valid loss 0.3056, cost 0.2 min\n",
      "[[04/23/2020 19:27:55]] epoch 621 / 1500, batch 100%, train loss 0.1877, valid loss 0.3094, cost 0.3 min\n",
      "[[04/23/2020 19:28:17]] epoch 622 / 1500, batch 100%, train loss 0.7355, valid loss 0.2794, cost 0.4 min\n",
      "[[04/23/2020 19:28:42]] epoch 623 / 1500, batch 100%, train loss 0.1282, valid loss 0.3016, cost 0.4 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 19:29:00]] epoch 624 / 1500, batch 100%, train loss 0.1686, valid loss 0.2940, cost 0.3 min\n",
      "[[04/23/2020 19:29:17]] epoch 625 / 1500, batch 100%, train loss 0.0554, valid loss 0.2876, cost 0.3 min\n",
      "[[04/23/2020 19:29:37]] epoch 626 / 1500, batch 100%, train loss 0.4859, valid loss 0.2774, cost 0.3 min\n",
      "[[04/23/2020 19:29:52]] epoch 627 / 1500, batch 100%, train loss 0.1602, valid loss 0.2914, cost 0.2 min\n",
      "[[04/23/2020 19:30:10]] epoch 628 / 1500, batch 100%, train loss 0.1447, valid loss 0.2946, cost 0.3 min\n",
      "[[04/23/2020 19:30:24]] epoch 629 / 1500, batch 100%, train loss 0.0923, valid loss 0.2942, cost 0.2 min\n",
      "[[04/23/2020 19:30:38]] epoch 630 / 1500, batch 100%, train loss 0.0785, valid loss 0.2870, cost 0.2 min\n",
      "[[04/23/2020 19:30:56]] epoch 631 / 1500, batch 100%, train loss 0.2551, valid loss 0.2835, cost 0.3 min\n",
      "[[04/23/2020 19:31:16]] epoch 632 / 1500, batch 100%, train loss 0.1943, valid loss 0.2761, cost 0.3 min\n",
      "[[04/23/2020 19:31:34]] epoch 633 / 1500, batch 100%, train loss 0.0993, valid loss 0.2777, cost 0.3 min\n",
      "[[04/23/2020 19:31:47]] epoch 634 / 1500, batch 100%, train loss 0.1893, valid loss 0.2707, cost 0.2 min\n",
      "[[04/23/2020 19:32:05]] epoch 635 / 1500, batch 100%, train loss 0.1440, valid loss 0.2682, cost 0.3 min\n",
      "[[04/23/2020 19:32:22]] epoch 636 / 1500, batch 100%, train loss 0.1420, valid loss 0.2751, cost 0.3 min\n",
      "[[04/23/2020 19:32:41]] epoch 637 / 1500, batch 100%, train loss 0.2946, valid loss 0.2955, cost 0.3 min\n",
      "[[04/23/2020 19:32:58]] epoch 638 / 1500, batch 100%, train loss 0.1248, valid loss 0.3137, cost 0.3 min\n",
      "[[04/23/2020 19:33:17]] epoch 639 / 1500, batch 100%, train loss 0.7617, valid loss 0.3329, cost 0.3 min\n",
      "[[04/23/2020 19:33:36]] epoch 640 / 1500, batch 100%, train loss 0.0666, valid loss 0.3409, cost 0.3 min\n",
      "[[04/23/2020 19:33:55]] epoch 641 / 1500, batch 100%, train loss 0.1654, valid loss 0.3208, cost 0.3 min\n",
      "[[04/23/2020 19:34:14]] epoch 642 / 1500, batch 100%, train loss 0.1938, valid loss 0.3070, cost 0.3 min\n",
      "[[04/23/2020 19:34:34]] epoch 643 / 1500, batch 100%, train loss 0.2409, valid loss 0.2794, cost 0.3 min\n",
      "[[04/23/2020 19:34:50]] epoch 644 / 1500, batch 100%, train loss 0.2509, valid loss 0.2761, cost 0.3 min\n",
      "[[04/23/2020 19:35:08]] epoch 645 / 1500, batch 100%, train loss 0.4266, valid loss 0.2882, cost 0.3 min\n",
      "[[04/23/2020 19:35:23]] epoch 646 / 1500, batch 100%, train loss 0.2039, valid loss 0.2941, cost 0.3 min\n",
      "[[04/23/2020 19:35:41]] epoch 647 / 1500, batch 100%, train loss 0.3445, valid loss 0.3141, cost 0.3 min\n",
      "[[04/23/2020 19:35:58]] epoch 648 / 1500, batch 100%, train loss 0.1416, valid loss 0.3065, cost 0.3 min\n",
      "[[04/23/2020 19:36:14]] epoch 649 / 1500, batch 100%, train loss 0.0682, valid loss 0.3023, cost 0.3 min\n",
      "[[04/23/2020 19:36:28]] epoch 650 / 1500, batch 100%, train loss 0.0847, valid loss 0.2991, cost 0.2 min\n",
      "[[04/23/2020 19:36:43]] epoch 651 / 1500, batch 100%, train loss 0.0291, valid loss 0.2977, cost 0.3 min\n",
      "[[04/23/2020 19:37:02]] epoch 652 / 1500, batch 100%, train loss 0.1536, valid loss 0.2965, cost 0.3 min\n",
      "[[04/23/2020 19:37:20]] epoch 653 / 1500, batch 100%, train loss 0.1358, valid loss 0.2985, cost 0.3 min\n",
      "[[04/23/2020 19:37:34]] epoch 654 / 1500, batch 100%, train loss 0.1454, valid loss 0.2934, cost 0.2 min\n",
      "[[04/23/2020 19:37:49]] epoch 655 / 1500, batch 100%, train loss 0.1769, valid loss 0.2906, cost 0.3 min\n",
      "[[04/23/2020 19:38:07]] epoch 656 / 1500, batch 100%, train loss 0.0909, valid loss 0.2869, cost 0.3 min\n",
      "[[04/23/2020 19:38:27]] epoch 657 / 1500, batch 100%, train loss 0.6027, valid loss 0.2796, cost 0.3 min\n",
      "[[04/23/2020 19:38:47]] epoch 658 / 1500, batch 100%, train loss 0.2678, valid loss 0.2804, cost 0.3 min\n",
      "[[04/23/2020 19:39:03]] epoch 659 / 1500, batch 100%, train loss 0.0816, valid loss 0.2972, cost 0.3 min\n",
      "[[04/23/2020 19:39:21]] epoch 660 / 1500, batch 100%, train loss 0.0936, valid loss 0.2895, cost 0.3 min\n",
      "[[04/23/2020 19:39:39]] epoch 661 / 1500, batch 100%, train loss 0.1899, valid loss 0.2868, cost 0.3 min\n",
      "[[04/23/2020 19:40:00]] epoch 662 / 1500, batch 100%, train loss 0.3747, valid loss 0.2979, cost 0.4 min\n",
      "[[04/23/2020 19:40:20]] epoch 663 / 1500, batch 100%, train loss 0.5126, valid loss 0.3285, cost 0.3 min\n",
      "[[04/23/2020 19:40:37]] epoch 664 / 1500, batch 100%, train loss 0.1648, valid loss 0.3336, cost 0.3 min\n",
      "[[04/23/2020 19:40:54]] epoch 665 / 1500, batch 100%, train loss 0.4430, valid loss 0.3121, cost 0.3 min\n",
      "[[04/23/2020 19:41:11]] epoch 666 / 1500, batch 100%, train loss 0.5497, valid loss 0.2975, cost 0.3 min\n",
      "[[04/23/2020 19:41:28]] epoch 667 / 1500, batch 100%, train loss 0.0936, valid loss 0.2865, cost 0.3 min\n",
      "[[04/23/2020 19:41:47]] epoch 668 / 1500, batch 100%, train loss 0.1245, valid loss 0.2956, cost 0.3 min\n",
      "[[04/23/2020 19:42:03]] epoch 669 / 1500, batch 100%, train loss 0.5886, valid loss 0.2911, cost 0.3 min\n",
      "[[04/23/2020 19:42:18]] epoch 670 / 1500, batch 100%, train loss 0.1490, valid loss 0.2900, cost 0.3 min\n",
      "[[04/23/2020 19:42:37]] epoch 671 / 1500, batch 100%, train loss 0.1703, valid loss 0.2858, cost 0.3 min\n",
      "[[04/23/2020 19:42:56]] epoch 672 / 1500, batch 100%, train loss 0.1321, valid loss 0.2757, cost 0.3 min\n",
      "[[04/23/2020 19:43:14]] epoch 673 / 1500, batch 100%, train loss 0.1361, valid loss 0.2799, cost 0.3 min\n",
      "[[04/23/2020 19:43:32]] epoch 674 / 1500, batch 100%, train loss 0.0857, valid loss 0.2748, cost 0.3 min\n",
      "[[04/23/2020 19:43:47]] epoch 675 / 1500, batch 100%, train loss 0.1484, valid loss 0.2779, cost 0.3 min\n",
      "[[04/23/2020 19:44:04]] epoch 676 / 1500, batch 100%, train loss 0.2585, valid loss 0.2716, cost 0.3 min\n",
      "[[04/23/2020 19:44:21]] epoch 677 / 1500, batch 100%, train loss 0.2007, valid loss 0.2767, cost 0.3 min\n",
      "[[04/23/2020 19:44:38]] epoch 678 / 1500, batch 100%, train loss 0.2119, valid loss 0.2646, cost 0.3 min\n",
      "[[04/23/2020 19:44:57]] epoch 679 / 1500, batch 100%, train loss 0.1372, valid loss 0.2735, cost 0.3 min\n",
      "[[04/23/2020 19:45:14]] epoch 680 / 1500, batch 100%, train loss 0.2760, valid loss 0.2772, cost 0.3 min\n",
      "[[04/23/2020 19:45:33]] epoch 681 / 1500, batch 100%, train loss 0.0917, valid loss 0.2786, cost 0.3 min\n",
      "[[04/23/2020 19:45:48]] epoch 682 / 1500, batch 100%, train loss 0.2686, valid loss 0.2730, cost 0.2 min\n",
      "[[04/23/2020 19:46:06]] epoch 683 / 1500, batch 100%, train loss 0.1289, valid loss 0.2745, cost 0.3 min\n",
      "[[04/23/2020 19:46:22]] epoch 684 / 1500, batch 100%, train loss 0.1771, valid loss 0.2727, cost 0.3 min\n",
      "[[04/23/2020 19:46:35]] epoch 685 / 1500, batch 100%, train loss 0.0862, valid loss 0.2738, cost 0.2 min\n",
      "[[04/23/2020 19:46:52]] epoch 686 / 1500, batch 100%, train loss 0.1401, valid loss 0.2744, cost 0.3 min\n",
      "[[04/23/2020 19:47:10]] epoch 687 / 1500, batch 100%, train loss 0.1689, valid loss 0.2747, cost 0.3 min\n",
      "[[04/23/2020 19:47:28]] epoch 688 / 1500, batch 100%, train loss 0.0526, valid loss 0.2685, cost 0.3 min\n",
      "[[04/23/2020 19:47:44]] epoch 689 / 1500, batch 100%, train loss 0.1097, valid loss 0.2763, cost 0.3 min\n",
      "[[04/23/2020 19:48:00]] epoch 690 / 1500, batch 100%, train loss 0.0588, valid loss 0.2743, cost 0.3 min\n",
      "[[04/23/2020 19:48:23]] epoch 691 / 1500, batch 100%, train loss 0.3250, valid loss 0.2757, cost 0.4 min\n",
      "[[04/23/2020 19:48:43]] epoch 692 / 1500, batch 100%, train loss 0.0571, valid loss 0.2773, cost 0.3 min\n",
      "[[04/23/2020 19:48:58]] epoch 693 / 1500, batch 100%, train loss 0.7045, valid loss 0.2737, cost 0.2 min\n",
      "[[04/23/2020 19:49:10]] epoch 694 / 1500, batch 100%, train loss 0.2268, valid loss 0.2749, cost 0.2 min\n",
      "[[04/23/2020 19:49:25]] epoch 695 / 1500, batch 100%, train loss 0.0937, valid loss 0.2766, cost 0.2 min\n",
      "[[04/23/2020 19:49:39]] epoch 696 / 1500, batch 100%, train loss 0.0797, valid loss 0.2766, cost 0.2 min\n",
      "[[04/23/2020 19:49:53]] epoch 697 / 1500, batch 100%, train loss 0.1802, valid loss 0.2743, cost 0.2 min\n",
      "[[04/23/2020 19:50:10]] epoch 698 / 1500, batch 100%, train loss 0.3181, valid loss 0.2769, cost 0.3 min\n",
      "[[04/23/2020 19:50:29]] epoch 699 / 1500, batch 100%, train loss 0.1078, valid loss 0.2758, cost 0.3 min\n",
      "[[04/23/2020 19:50:44]] epoch 700 / 1500, batch 100%, train loss 0.1148, valid loss 0.2779, cost 0.3 min\n",
      "[[04/23/2020 19:50:57]] epoch 701 / 1500, batch 100%, train loss 0.1844, valid loss 0.2767, cost 0.2 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 19:51:17]] epoch 702 / 1500, batch 100%, train loss 0.1251, valid loss 0.2772, cost 0.3 min\n",
      "[[04/23/2020 19:51:35]] epoch 703 / 1500, batch 100%, train loss 0.1607, valid loss 0.2790, cost 0.3 min\n",
      "[[04/23/2020 19:51:53]] epoch 704 / 1500, batch 100%, train loss 0.2061, valid loss 0.2773, cost 0.3 min\n",
      "[[04/23/2020 19:52:12]] epoch 705 / 1500, batch 100%, train loss 0.3564, valid loss 0.2753, cost 0.3 min\n",
      "[[04/23/2020 19:52:34]] epoch 706 / 1500, batch 100%, train loss 0.4090, valid loss 0.2766, cost 0.4 min\n",
      "[[04/23/2020 19:52:55]] epoch 707 / 1500, batch 100%, train loss 0.1673, valid loss 0.2799, cost 0.4 min\n",
      "[[04/23/2020 19:53:13]] epoch 708 / 1500, batch 100%, train loss 0.0553, valid loss 0.2759, cost 0.3 min\n",
      "[[04/23/2020 19:53:30]] epoch 709 / 1500, batch 100%, train loss 0.1297, valid loss 0.2811, cost 0.3 min\n",
      "[[04/23/2020 19:53:43]] epoch 710 / 1500, batch 100%, train loss 0.3599, valid loss 0.2817, cost 0.2 min\n",
      "[[04/23/2020 19:54:00]] epoch 711 / 1500, batch 100%, train loss 0.2986, valid loss 0.2835, cost 0.3 min\n",
      "[[04/23/2020 19:54:17]] epoch 712 / 1500, batch 100%, train loss 0.3429, valid loss 0.2834, cost 0.3 min\n",
      "[[04/23/2020 19:54:32]] epoch 713 / 1500, batch 100%, train loss 0.5448, valid loss 0.2854, cost 0.2 min\n",
      "[[04/23/2020 19:54:48]] epoch 714 / 1500, batch 100%, train loss 0.0554, valid loss 0.2811, cost 0.3 min\n",
      "[[04/23/2020 19:55:08]] epoch 715 / 1500, batch 100%, train loss 0.6097, valid loss 0.2848, cost 0.3 min\n",
      "[[04/23/2020 19:55:27]] epoch 716 / 1500, batch 100%, train loss 1.2911, valid loss 0.2888, cost 0.3 min\n",
      "[[04/23/2020 19:55:46]] epoch 717 / 1500, batch 100%, train loss 0.1861, valid loss 0.2841, cost 0.3 min\n",
      "[[04/23/2020 19:56:01]] epoch 718 / 1500, batch 100%, train loss 0.2188, valid loss 0.2812, cost 0.3 min\n",
      "[[04/23/2020 19:56:17]] epoch 719 / 1500, batch 100%, train loss 0.2158, valid loss 0.2804, cost 0.3 min\n",
      "[[04/23/2020 19:56:32]] epoch 720 / 1500, batch 100%, train loss 0.2999, valid loss 0.2781, cost 0.2 min\n",
      "[[04/23/2020 19:56:44]] epoch 721 / 1500, batch 100%, train loss 0.1912, valid loss 0.2774, cost 0.2 min\n",
      "[[04/23/2020 19:57:02]] epoch 722 / 1500, batch 100%, train loss 0.0763, valid loss 0.2727, cost 0.3 min\n",
      "[[04/23/2020 19:57:17]] epoch 723 / 1500, batch 100%, train loss 0.1359, valid loss 0.2706, cost 0.3 min\n",
      "[[04/23/2020 19:57:33]] epoch 724 / 1500, batch 100%, train loss 0.2920, valid loss 0.2685, cost 0.3 min\n",
      "[[04/23/2020 19:57:46]] epoch 725 / 1500, batch 100%, train loss 0.0979, valid loss 0.2707, cost 0.2 min\n",
      "[[04/23/2020 19:58:03]] epoch 726 / 1500, batch 100%, train loss 0.2136, valid loss 0.2755, cost 0.3 min\n",
      "[[04/23/2020 19:58:21]] epoch 727 / 1500, batch 100%, train loss 0.5302, valid loss 0.2775, cost 0.3 min\n",
      "[[04/23/2020 19:58:39]] epoch 728 / 1500, batch 100%, train loss 0.2735, valid loss 0.2742, cost 0.3 min\n",
      "[[04/23/2020 19:58:55]] epoch 729 / 1500, batch 100%, train loss 0.0981, valid loss 0.2772, cost 0.3 min\n",
      "[[04/23/2020 19:59:12]] epoch 730 / 1500, batch 100%, train loss 0.2445, valid loss 0.2774, cost 0.3 min\n",
      "[[04/23/2020 19:59:29]] epoch 731 / 1500, batch 100%, train loss 0.2493, valid loss 0.2822, cost 0.3 min\n",
      "[[04/23/2020 19:59:48]] epoch 732 / 1500, batch 100%, train loss 0.1195, valid loss 0.2727, cost 0.3 min\n",
      "[[04/23/2020 20:00:04]] epoch 733 / 1500, batch 100%, train loss 0.0805, valid loss 0.2791, cost 0.3 min\n",
      "[[04/23/2020 20:00:21]] epoch 734 / 1500, batch 100%, train loss 0.1249, valid loss 0.2771, cost 0.3 min\n",
      "[[04/23/2020 20:00:37]] epoch 735 / 1500, batch 100%, train loss 0.1250, valid loss 0.2777, cost 0.3 min\n",
      "[[04/23/2020 20:00:52]] epoch 736 / 1500, batch 100%, train loss 0.0443, valid loss 0.2775, cost 0.3 min\n",
      "[[04/23/2020 20:01:08]] epoch 737 / 1500, batch 100%, train loss 0.2852, valid loss 0.2783, cost 0.3 min\n",
      "[[04/23/2020 20:01:30]] epoch 738 / 1500, batch 100%, train loss 0.0459, valid loss 0.2745, cost 0.4 min\n",
      "[[04/23/2020 20:01:49]] epoch 739 / 1500, batch 100%, train loss 0.3774, valid loss 0.2772, cost 0.3 min\n",
      "[[04/23/2020 20:02:09]] epoch 740 / 1500, batch 100%, train loss 0.1173, valid loss 0.2848, cost 0.3 min\n",
      "[[04/23/2020 20:02:28]] epoch 741 / 1500, batch 100%, train loss 0.0749, valid loss 0.2904, cost 0.3 min\n",
      "[[04/23/2020 20:02:46]] epoch 742 / 1500, batch 100%, train loss 0.0991, valid loss 0.2958, cost 0.3 min\n",
      "[[04/23/2020 20:03:02]] epoch 743 / 1500, batch 100%, train loss 0.1250, valid loss 0.3029, cost 0.3 min\n",
      "[[04/23/2020 20:03:21]] epoch 744 / 1500, batch 100%, train loss 0.2227, valid loss 0.2875, cost 0.3 min\n",
      "[[04/23/2020 20:03:40]] epoch 745 / 1500, batch 100%, train loss 0.4163, valid loss 0.2771, cost 0.3 min\n",
      "[[04/23/2020 20:03:59]] epoch 746 / 1500, batch 100%, train loss 0.1099, valid loss 0.2788, cost 0.3 min\n",
      "[[04/23/2020 20:04:19]] epoch 747 / 1500, batch 100%, train loss 0.1105, valid loss 0.2712, cost 0.3 min\n",
      "[[04/23/2020 20:04:41]] epoch 748 / 1500, batch 100%, train loss 0.1542, valid loss 0.2735, cost 0.4 min\n",
      "[[04/23/2020 20:04:57]] epoch 749 / 1500, batch 100%, train loss 0.0516, valid loss 0.2711, cost 0.3 min\n",
      "[[04/23/2020 20:05:13]] epoch 750 / 1500, batch 100%, train loss 0.0588, valid loss 0.2755, cost 0.3 min\n",
      "[[04/23/2020 20:05:31]] epoch 751 / 1500, batch 100%, train loss 0.0636, valid loss 0.2712, cost 0.3 min\n",
      "[[04/23/2020 20:05:46]] epoch 752 / 1500, batch 100%, train loss 0.2792, valid loss 0.2708, cost 0.2 min\n",
      "[[04/23/2020 20:06:04]] epoch 753 / 1500, batch 100%, train loss 0.1838, valid loss 0.2828, cost 0.3 min\n",
      "[[04/23/2020 20:06:22]] epoch 754 / 1500, batch 100%, train loss 0.0605, valid loss 0.2812, cost 0.3 min\n",
      "[[04/23/2020 20:06:37]] epoch 755 / 1500, batch 100%, train loss 0.0727, valid loss 0.2867, cost 0.2 min\n",
      "[[04/23/2020 20:06:54]] epoch 756 / 1500, batch 100%, train loss 0.2412, valid loss 0.2770, cost 0.3 min\n",
      "[[04/23/2020 20:07:13]] epoch 757 / 1500, batch 100%, train loss 0.2889, valid loss 0.2776, cost 0.3 min\n",
      "[[04/23/2020 20:07:30]] epoch 758 / 1500, batch 100%, train loss 0.0944, valid loss 0.2775, cost 0.3 min\n",
      "[[04/23/2020 20:07:42]] epoch 759 / 1500, batch 100%, train loss 0.0779, valid loss 0.2751, cost 0.2 min\n",
      "[[04/23/2020 20:07:59]] epoch 760 / 1500, batch 100%, train loss 0.1322, valid loss 0.2788, cost 0.3 min\n",
      "[[04/23/2020 20:08:17]] epoch 761 / 1500, batch 100%, train loss 0.1305, valid loss 0.2770, cost 0.3 min\n",
      "[[04/23/2020 20:08:37]] epoch 762 / 1500, batch 100%, train loss 0.1342, valid loss 0.2725, cost 0.3 min\n",
      "[[04/23/2020 20:08:53]] epoch 763 / 1500, batch 100%, train loss 0.2005, valid loss 0.2684, cost 0.3 min\n",
      "[[04/23/2020 20:09:09]] epoch 764 / 1500, batch 100%, train loss 0.1005, valid loss 0.2778, cost 0.3 min\n",
      "[[04/23/2020 20:09:25]] epoch 765 / 1500, batch 100%, train loss 0.1519, valid loss 0.2709, cost 0.3 min\n",
      "[[04/23/2020 20:09:43]] epoch 766 / 1500, batch 100%, train loss 0.3028, valid loss 0.2664, cost 0.3 min\n",
      "[[04/23/2020 20:10:00]] epoch 767 / 1500, batch 100%, train loss 0.7120, valid loss 0.2740, cost 0.3 min\n",
      "[[04/23/2020 20:10:14]] epoch 768 / 1500, batch 100%, train loss 0.1991, valid loss 0.2851, cost 0.2 min\n",
      "[[04/23/2020 20:10:33]] epoch 769 / 1500, batch 100%, train loss 0.2199, valid loss 0.2842, cost 0.3 min\n",
      "[[04/23/2020 20:10:52]] epoch 770 / 1500, batch 100%, train loss 0.1111, valid loss 0.2767, cost 0.3 min\n",
      "[[04/23/2020 20:11:10]] epoch 771 / 1500, batch 100%, train loss 0.1375, valid loss 0.2796, cost 0.3 min\n",
      "[[04/23/2020 20:11:28]] epoch 772 / 1500, batch 100%, train loss 0.1071, valid loss 0.2844, cost 0.3 min\n",
      "[[04/23/2020 20:11:46]] epoch 773 / 1500, batch 100%, train loss 0.0800, valid loss 0.2887, cost 0.3 min\n",
      "[[04/23/2020 20:12:05]] epoch 774 / 1500, batch 100%, train loss 0.2153, valid loss 0.2746, cost 0.3 min\n",
      "[[04/23/2020 20:12:23]] epoch 775 / 1500, batch 100%, train loss 0.2666, valid loss 0.2739, cost 0.3 min\n",
      "[[04/23/2020 20:12:43]] epoch 776 / 1500, batch 100%, train loss 0.1928, valid loss 0.2669, cost 0.3 min\n",
      "[[04/23/2020 20:12:58]] epoch 777 / 1500, batch 100%, train loss 0.2624, valid loss 0.2743, cost 0.2 min\n",
      "[[04/23/2020 20:13:14]] epoch 778 / 1500, batch 100%, train loss 0.2715, valid loss 0.2666, cost 0.3 min\n",
      "[[04/23/2020 20:13:33]] epoch 779 / 1500, batch 100%, train loss 0.3976, valid loss 0.2661, cost 0.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 20:13:52]] epoch 780 / 1500, batch 100%, train loss 0.1037, valid loss 0.2688, cost 0.3 min\n",
      "[[04/23/2020 20:14:06]] epoch 781 / 1500, batch 100%, train loss 0.4001, valid loss 0.2670, cost 0.2 min\n",
      "[[04/23/2020 20:14:25]] epoch 782 / 1500, batch 100%, train loss 0.0147, valid loss 0.2813, cost 0.3 min\n",
      "[[04/23/2020 20:14:44]] epoch 783 / 1500, batch 100%, train loss 0.3448, valid loss 0.2853, cost 0.3 min\n",
      "[[04/23/2020 20:15:06]] epoch 784 / 1500, batch 100%, train loss 0.1013, valid loss 0.2787, cost 0.4 min\n",
      "[[04/23/2020 20:15:25]] epoch 785 / 1500, batch 100%, train loss 0.0689, valid loss 0.2775, cost 0.3 min\n",
      "[[04/23/2020 20:15:42]] epoch 786 / 1500, batch 100%, train loss 0.0913, valid loss 0.2695, cost 0.3 min\n",
      "[[04/23/2020 20:15:54]] epoch 787 / 1500, batch 100%, train loss 0.0921, valid loss 0.2667, cost 0.2 min\n",
      "[[04/23/2020 20:16:13]] epoch 788 / 1500, batch 100%, train loss 0.1932, valid loss 0.2666, cost 0.3 min\n",
      "[[04/23/2020 20:16:32]] epoch 789 / 1500, batch 100%, train loss 0.1310, valid loss 0.2688, cost 0.3 min\n",
      "[[04/23/2020 20:16:50]] epoch 790 / 1500, batch 100%, train loss 0.1788, valid loss 0.2708, cost 0.3 min\n",
      "[[04/23/2020 20:17:06]] epoch 791 / 1500, batch 100%, train loss 0.1925, valid loss 0.2671, cost 0.3 min\n",
      "[[04/23/2020 20:17:25]] epoch 792 / 1500, batch 100%, train loss 0.3032, valid loss 0.2689, cost 0.3 min\n",
      "[[04/23/2020 20:17:43]] epoch 793 / 1500, batch 100%, train loss 0.0705, valid loss 0.2829, cost 0.3 min\n",
      "[[04/23/2020 20:18:02]] epoch 794 / 1500, batch 100%, train loss 0.0896, valid loss 0.2873, cost 0.3 min\n",
      "[[04/23/2020 20:18:20]] epoch 795 / 1500, batch 100%, train loss 0.3616, valid loss 0.2734, cost 0.3 min\n",
      "[[04/23/2020 20:18:33]] epoch 796 / 1500, batch 100%, train loss 0.1427, valid loss 0.2667, cost 0.2 min\n",
      "[[04/23/2020 20:18:50]] epoch 797 / 1500, batch 100%, train loss 0.5034, valid loss 0.2739, cost 0.3 min\n",
      "[[04/23/2020 20:19:08]] epoch 798 / 1500, batch 100%, train loss 0.1612, valid loss 0.2741, cost 0.3 min\n",
      "[[04/23/2020 20:19:25]] epoch 799 / 1500, batch 100%, train loss 0.0929, valid loss 0.2748, cost 0.3 min\n",
      "[[04/23/2020 20:19:43]] epoch 800 / 1500, batch 100%, train loss 0.2807, valid loss 0.2727, cost 0.3 min\n",
      "[[04/23/2020 20:20:02]] epoch 801 / 1500, batch 100%, train loss 0.0913, valid loss 0.2739, cost 0.3 min\n",
      "[[04/23/2020 20:20:23]] epoch 802 / 1500, batch 100%, train loss 0.0789, valid loss 0.2679, cost 0.4 min\n",
      "[[04/23/2020 20:20:39]] epoch 803 / 1500, batch 100%, train loss 0.0188, valid loss 0.2651, cost 0.3 min\n",
      "[[04/23/2020 20:20:58]] epoch 804 / 1500, batch 100%, train loss 0.1310, valid loss 0.2681, cost 0.3 min\n",
      "[[04/23/2020 20:21:11]] epoch 805 / 1500, batch 100%, train loss 0.3090, valid loss 0.2685, cost 0.2 min\n",
      "[[04/23/2020 20:21:27]] epoch 806 / 1500, batch 100%, train loss 0.0598, valid loss 0.2672, cost 0.3 min\n",
      "[[04/23/2020 20:21:45]] epoch 807 / 1500, batch 100%, train loss 0.1589, valid loss 0.2674, cost 0.3 min\n",
      "[[04/23/2020 20:22:02]] epoch 808 / 1500, batch 100%, train loss 0.1567, valid loss 0.2689, cost 0.3 min\n",
      "[[04/23/2020 20:22:21]] epoch 809 / 1500, batch 100%, train loss 0.0310, valid loss 0.2681, cost 0.3 min\n",
      "[[04/23/2020 20:22:39]] epoch 810 / 1500, batch 100%, train loss 0.3815, valid loss 0.2740, cost 0.3 min\n",
      "[[04/23/2020 20:23:00]] epoch 811 / 1500, batch 100%, train loss 0.1944, valid loss 0.2713, cost 0.3 min\n",
      "[[04/23/2020 20:23:21]] epoch 812 / 1500, batch 100%, train loss 0.1184, valid loss 0.2770, cost 0.3 min\n",
      "[[04/23/2020 20:23:42]] epoch 813 / 1500, batch 100%, train loss 0.4676, valid loss 0.2789, cost 0.3 min\n",
      "[[04/23/2020 20:24:03]] epoch 814 / 1500, batch 100%, train loss 0.3080, valid loss 0.2744, cost 0.4 min\n",
      "[[04/23/2020 20:24:24]] epoch 815 / 1500, batch 100%, train loss 0.4383, valid loss 0.2744, cost 0.4 min\n",
      "[[04/23/2020 20:24:42]] epoch 816 / 1500, batch 100%, train loss 0.1309, valid loss 0.2721, cost 0.3 min\n",
      "[[04/23/2020 20:25:00]] epoch 817 / 1500, batch 100%, train loss 0.3051, valid loss 0.2718, cost 0.3 min\n",
      "[[04/23/2020 20:25:18]] epoch 818 / 1500, batch 100%, train loss 0.1453, valid loss 0.2717, cost 0.3 min\n",
      "[[04/23/2020 20:25:35]] epoch 819 / 1500, batch 100%, train loss 0.2488, valid loss 0.2752, cost 0.3 min\n",
      "[[04/23/2020 20:25:53]] epoch 820 / 1500, batch 100%, train loss 0.2355, valid loss 0.2765, cost 0.3 min\n",
      "[[04/23/2020 20:26:13]] epoch 821 / 1500, batch 100%, train loss 0.2745, valid loss 0.2752, cost 0.3 min\n",
      "[[04/23/2020 20:26:33]] epoch 822 / 1500, batch 100%, train loss 0.1902, valid loss 0.2752, cost 0.3 min\n",
      "[[04/23/2020 20:26:52]] epoch 823 / 1500, batch 100%, train loss 0.1975, valid loss 0.2723, cost 0.3 min\n",
      "[[04/23/2020 20:27:14]] epoch 824 / 1500, batch 100%, train loss 0.0363, valid loss 0.2758, cost 0.4 min\n",
      "[[04/23/2020 20:27:29]] epoch 825 / 1500, batch 100%, train loss 0.1196, valid loss 0.2732, cost 0.3 min\n",
      "[[04/23/2020 20:27:45]] epoch 826 / 1500, batch 100%, train loss 0.0953, valid loss 0.2727, cost 0.3 min\n",
      "[[04/23/2020 20:28:02]] epoch 827 / 1500, batch 100%, train loss 0.1011, valid loss 0.2757, cost 0.3 min\n",
      "[[04/23/2020 20:28:22]] epoch 828 / 1500, batch 100%, train loss 0.0992, valid loss 0.2802, cost 0.3 min\n",
      "[[04/23/2020 20:28:42]] epoch 829 / 1500, batch 100%, train loss 0.2276, valid loss 0.2754, cost 0.3 min\n",
      "[[04/23/2020 20:29:00]] epoch 830 / 1500, batch 100%, train loss 0.2622, valid loss 0.2802, cost 0.3 min\n",
      "[[04/23/2020 20:29:23]] epoch 831 / 1500, batch 100%, train loss 0.2085, valid loss 0.2802, cost 0.4 min\n",
      "[[04/23/2020 20:29:40]] epoch 832 / 1500, batch 100%, train loss 0.6178, valid loss 0.2721, cost 0.3 min\n",
      "[[04/23/2020 20:30:01]] epoch 833 / 1500, batch 100%, train loss 0.3499, valid loss 0.2741, cost 0.3 min\n",
      "[[04/23/2020 20:30:16]] epoch 834 / 1500, batch 100%, train loss 0.0496, valid loss 0.2748, cost 0.3 min\n",
      "[[04/23/2020 20:30:34]] epoch 835 / 1500, batch 100%, train loss 0.3372, valid loss 0.2727, cost 0.3 min\n",
      "[[04/23/2020 20:30:50]] epoch 836 / 1500, batch 100%, train loss 0.1139, valid loss 0.2742, cost 0.3 min\n",
      "[[04/23/2020 20:31:07]] epoch 837 / 1500, batch 100%, train loss 0.1099, valid loss 0.2791, cost 0.3 min\n",
      "[[04/23/2020 20:31:24]] epoch 838 / 1500, batch 100%, train loss 0.1379, valid loss 0.2741, cost 0.3 min\n",
      "[[04/23/2020 20:31:40]] epoch 839 / 1500, batch 100%, train loss 0.2902, valid loss 0.2751, cost 0.3 min\n",
      "[[04/23/2020 20:31:57]] epoch 840 / 1500, batch 100%, train loss 0.1113, valid loss 0.2730, cost 0.3 min\n",
      "[[04/23/2020 20:32:14]] epoch 841 / 1500, batch 100%, train loss 0.1903, valid loss 0.2755, cost 0.3 min\n",
      "[[04/23/2020 20:32:28]] epoch 842 / 1500, batch 100%, train loss 0.0828, valid loss 0.2710, cost 0.2 min\n",
      "[[04/23/2020 20:32:45]] epoch 843 / 1500, batch 100%, train loss 0.1781, valid loss 0.2691, cost 0.3 min\n",
      "[[04/23/2020 20:32:58]] epoch 844 / 1500, batch 100%, train loss 0.0974, valid loss 0.2722, cost 0.2 min\n",
      "[[04/23/2020 20:33:16]] epoch 845 / 1500, batch 100%, train loss 0.1287, valid loss 0.2771, cost 0.3 min\n",
      "[[04/23/2020 20:33:29]] epoch 846 / 1500, batch 100%, train loss 0.2595, valid loss 0.2729, cost 0.2 min\n",
      "[[04/23/2020 20:33:43]] epoch 847 / 1500, batch 100%, train loss 0.2008, valid loss 0.2730, cost 0.2 min\n",
      "[[04/23/2020 20:34:02]] epoch 848 / 1500, batch 100%, train loss 0.0722, valid loss 0.2731, cost 0.3 min\n",
      "[[04/23/2020 20:34:14]] epoch 849 / 1500, batch 100%, train loss 0.3595, valid loss 0.2700, cost 0.2 min\n",
      "[[04/23/2020 20:34:33]] epoch 850 / 1500, batch 100%, train loss 0.2231, valid loss 0.2706, cost 0.3 min\n",
      "[[04/23/2020 20:34:52]] epoch 851 / 1500, batch 100%, train loss 0.0905, valid loss 0.2747, cost 0.3 min\n",
      "[[04/23/2020 20:35:08]] epoch 852 / 1500, batch 100%, train loss 0.3237, valid loss 0.2705, cost 0.3 min\n",
      "[[04/23/2020 20:35:26]] epoch 853 / 1500, batch 100%, train loss 0.2449, valid loss 0.2809, cost 0.3 min\n",
      "[[04/23/2020 20:35:40]] epoch 854 / 1500, batch 100%, train loss 0.2529, valid loss 0.2711, cost 0.2 min\n",
      "[[04/23/2020 20:35:57]] epoch 855 / 1500, batch 100%, train loss 0.1904, valid loss 0.2711, cost 0.3 min\n",
      "[[04/23/2020 20:36:14]] epoch 856 / 1500, batch 100%, train loss 0.1340, valid loss 0.2701, cost 0.3 min\n",
      "[[04/23/2020 20:36:29]] epoch 857 / 1500, batch 100%, train loss 0.0443, valid loss 0.2683, cost 0.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 20:36:48]] epoch 858 / 1500, batch 100%, train loss 0.0612, valid loss 0.2781, cost 0.3 min\n",
      "[[04/23/2020 20:37:04]] epoch 859 / 1500, batch 100%, train loss 0.1371, valid loss 0.2712, cost 0.3 min\n",
      "[[04/23/2020 20:37:23]] epoch 860 / 1500, batch 100%, train loss 0.3264, valid loss 0.2757, cost 0.3 min\n",
      "[[04/23/2020 20:37:40]] epoch 861 / 1500, batch 100%, train loss 0.1223, valid loss 0.2774, cost 0.3 min\n",
      "[[04/23/2020 20:37:56]] epoch 862 / 1500, batch 100%, train loss 0.0953, valid loss 0.2821, cost 0.3 min\n",
      "[[04/23/2020 20:38:12]] epoch 863 / 1500, batch 100%, train loss 0.1594, valid loss 0.2802, cost 0.3 min\n",
      "[[04/23/2020 20:38:26]] epoch 864 / 1500, batch 100%, train loss 0.1248, valid loss 0.2802, cost 0.2 min\n",
      "[[04/23/2020 20:38:41]] epoch 865 / 1500, batch 100%, train loss 0.0425, valid loss 0.2769, cost 0.3 min\n",
      "[[04/23/2020 20:38:59]] epoch 866 / 1500, batch 100%, train loss 0.0716, valid loss 0.2770, cost 0.3 min\n",
      "[[04/23/2020 20:39:13]] epoch 867 / 1500, batch 100%, train loss 0.2177, valid loss 0.2798, cost 0.2 min\n",
      "[[04/23/2020 20:39:33]] epoch 868 / 1500, batch 100%, train loss 0.1032, valid loss 0.2791, cost 0.3 min\n",
      "[[04/23/2020 20:39:51]] epoch 869 / 1500, batch 100%, train loss 0.1080, valid loss 0.2779, cost 0.3 min\n",
      "[[04/23/2020 20:40:07]] epoch 870 / 1500, batch 100%, train loss 0.0744, valid loss 0.2755, cost 0.3 min\n",
      "[[04/23/2020 20:40:26]] epoch 871 / 1500, batch 100%, train loss 0.2109, valid loss 0.2755, cost 0.3 min\n",
      "[[04/23/2020 20:40:41]] epoch 872 / 1500, batch 100%, train loss 0.1740, valid loss 0.2781, cost 0.3 min\n",
      "[[04/23/2020 20:40:56]] epoch 873 / 1500, batch 100%, train loss 0.1041, valid loss 0.2850, cost 0.3 min\n",
      "[[04/23/2020 20:41:13]] epoch 874 / 1500, batch 100%, train loss 0.1036, valid loss 0.2804, cost 0.3 min\n",
      "[[04/23/2020 20:41:34]] epoch 875 / 1500, batch 100%, train loss 0.5645, valid loss 0.2738, cost 0.3 min\n",
      "[[04/23/2020 20:41:51]] epoch 876 / 1500, batch 100%, train loss 0.1837, valid loss 0.2689, cost 0.3 min\n",
      "[[04/23/2020 20:42:07]] epoch 877 / 1500, batch 100%, train loss 0.1364, valid loss 0.2662, cost 0.3 min\n",
      "[[04/23/2020 20:42:30]] epoch 878 / 1500, batch 100%, train loss 0.0902, valid loss 0.2707, cost 0.4 min\n",
      "[[04/23/2020 20:42:48]] epoch 879 / 1500, batch 100%, train loss 0.1111, valid loss 0.2775, cost 0.3 min\n",
      "[[04/23/2020 20:43:05]] epoch 880 / 1500, batch 100%, train loss 0.0317, valid loss 0.2726, cost 0.3 min\n",
      "[[04/23/2020 20:43:22]] epoch 881 / 1500, batch 100%, train loss 0.2416, valid loss 0.2714, cost 0.3 min\n",
      "[[04/23/2020 20:43:41]] epoch 882 / 1500, batch 100%, train loss 0.1314, valid loss 0.2751, cost 0.3 min\n",
      "[[04/23/2020 20:43:58]] epoch 883 / 1500, batch 100%, train loss 0.1997, valid loss 0.2785, cost 0.3 min\n",
      "[[04/23/2020 20:44:21]] epoch 884 / 1500, batch 100%, train loss 0.1024, valid loss 0.2758, cost 0.4 min\n",
      "[[04/23/2020 20:44:40]] epoch 885 / 1500, batch 100%, train loss 0.0803, valid loss 0.2788, cost 0.3 min\n",
      "[[04/23/2020 20:44:59]] epoch 886 / 1500, batch 100%, train loss 0.1198, valid loss 0.2857, cost 0.3 min\n",
      "[[04/23/2020 20:45:18]] epoch 887 / 1500, batch 100%, train loss 0.1369, valid loss 0.2814, cost 0.3 min\n",
      "[[04/23/2020 20:45:37]] epoch 888 / 1500, batch 100%, train loss 0.0499, valid loss 0.2779, cost 0.3 min\n",
      "[[04/23/2020 20:45:56]] epoch 889 / 1500, batch 100%, train loss 0.1175, valid loss 0.2797, cost 0.3 min\n",
      "[[04/23/2020 20:46:10]] epoch 890 / 1500, batch 100%, train loss 0.1848, valid loss 0.2756, cost 0.2 min\n",
      "[[04/23/2020 20:46:25]] epoch 891 / 1500, batch 100%, train loss 0.1973, valid loss 0.2743, cost 0.2 min\n",
      "[[04/23/2020 20:46:41]] epoch 892 / 1500, batch 100%, train loss 0.5705, valid loss 0.2760, cost 0.3 min\n",
      "[[04/23/2020 20:47:01]] epoch 893 / 1500, batch 100%, train loss 0.1222, valid loss 0.2721, cost 0.3 min\n",
      "[[04/23/2020 20:47:19]] epoch 894 / 1500, batch 100%, train loss 0.1511, valid loss 0.2742, cost 0.3 min\n",
      "[[04/23/2020 20:47:33]] epoch 895 / 1500, batch 100%, train loss 0.5586, valid loss 0.2688, cost 0.2 min\n",
      "[[04/23/2020 20:47:49]] epoch 896 / 1500, batch 100%, train loss 0.2495, valid loss 0.2662, cost 0.3 min\n",
      "[[04/23/2020 20:48:04]] epoch 897 / 1500, batch 100%, train loss 0.1043, valid loss 0.2693, cost 0.2 min\n",
      "[[04/23/2020 20:48:21]] epoch 898 / 1500, batch 100%, train loss 0.1941, valid loss 0.2780, cost 0.3 min\n",
      "[[04/23/2020 20:48:39]] epoch 899 / 1500, batch 100%, train loss 0.0798, valid loss 0.2826, cost 0.3 min\n",
      "[[04/23/2020 20:48:54]] epoch 900 / 1500, batch 100%, train loss 0.0305, valid loss 0.2806, cost 0.2 min\n",
      "[[04/23/2020 20:49:13]] epoch 901 / 1500, batch 100%, train loss 0.0863, valid loss 0.2829, cost 0.3 min\n",
      "[[04/23/2020 20:49:34]] epoch 902 / 1500, batch 100%, train loss 0.2841, valid loss 0.2780, cost 0.3 min\n",
      "[[04/23/2020 20:49:55]] epoch 903 / 1500, batch 100%, train loss 0.2323, valid loss 0.2817, cost 0.3 min\n",
      "[[04/23/2020 20:50:10]] epoch 904 / 1500, batch 100%, train loss 0.4728, valid loss 0.2819, cost 0.2 min\n",
      "[[04/23/2020 20:50:30]] epoch 905 / 1500, batch 100%, train loss 0.1703, valid loss 0.2851, cost 0.3 min\n",
      "[[04/23/2020 20:50:46]] epoch 906 / 1500, batch 100%, train loss 0.2224, valid loss 0.2803, cost 0.3 min\n",
      "[[04/23/2020 20:51:02]] epoch 907 / 1500, batch 100%, train loss 0.1444, valid loss 0.2952, cost 0.3 min\n",
      "[[04/23/2020 20:51:20]] epoch 908 / 1500, batch 100%, train loss 0.1066, valid loss 0.3095, cost 0.3 min\n",
      "[[04/23/2020 20:51:37]] epoch 909 / 1500, batch 100%, train loss 0.3194, valid loss 0.2962, cost 0.3 min\n",
      "[[04/23/2020 20:51:52]] epoch 910 / 1500, batch 100%, train loss 0.0433, valid loss 0.2870, cost 0.2 min\n",
      "[[04/23/2020 20:52:13]] epoch 911 / 1500, batch 100%, train loss 0.1272, valid loss 0.2773, cost 0.3 min\n",
      "[[04/23/2020 20:52:31]] epoch 912 / 1500, batch 100%, train loss 0.1161, valid loss 0.2783, cost 0.3 min\n",
      "[[04/23/2020 20:52:48]] epoch 913 / 1500, batch 100%, train loss 0.3082, valid loss 0.2704, cost 0.3 min\n",
      "[[04/23/2020 20:53:08]] epoch 914 / 1500, batch 100%, train loss 0.2155, valid loss 0.2631, cost 0.3 min\n",
      "[[04/23/2020 20:53:28]] epoch 915 / 1500, batch 100%, train loss 0.6138, valid loss 0.2688, cost 0.3 min\n",
      "[[04/23/2020 20:53:42]] epoch 916 / 1500, batch 100%, train loss 0.1610, valid loss 0.2665, cost 0.2 min\n",
      "[[04/23/2020 20:53:59]] epoch 917 / 1500, batch 100%, train loss 0.3314, valid loss 0.2678, cost 0.3 min\n",
      "[[04/23/2020 20:54:12]] epoch 918 / 1500, batch 100%, train loss 0.1715, valid loss 0.2882, cost 0.2 min\n",
      "[[04/23/2020 20:54:26]] epoch 919 / 1500, batch 100%, train loss 0.5232, valid loss 0.3078, cost 0.2 min\n",
      "[[04/23/2020 20:54:48]] epoch 920 / 1500, batch 100%, train loss 0.1509, valid loss 0.3242, cost 0.4 min\n",
      "[[04/23/2020 20:55:04]] epoch 921 / 1500, batch 100%, train loss 0.1262, valid loss 0.3194, cost 0.3 min\n",
      "[[04/23/2020 20:55:23]] epoch 922 / 1500, batch 100%, train loss 0.1198, valid loss 0.3092, cost 0.3 min\n",
      "[[04/23/2020 20:55:36]] epoch 923 / 1500, batch 100%, train loss 0.1613, valid loss 0.3093, cost 0.2 min\n",
      "[[04/23/2020 20:55:51]] epoch 924 / 1500, batch 100%, train loss 0.1056, valid loss 0.3018, cost 0.2 min\n",
      "[[04/23/2020 20:56:07]] epoch 925 / 1500, batch 100%, train loss 0.2245, valid loss 0.2884, cost 0.3 min\n",
      "[[04/23/2020 20:56:29]] epoch 926 / 1500, batch 100%, train loss 0.7278, valid loss 0.2681, cost 0.4 min\n",
      "[[04/23/2020 20:56:49]] epoch 927 / 1500, batch 100%, train loss 0.1967, valid loss 0.2575, cost 0.3 min\n",
      "[[04/23/2020 20:57:05]] epoch 928 / 1500, batch 100%, train loss 0.4786, valid loss 0.2622, cost 0.3 min\n",
      "[[04/23/2020 20:57:24]] epoch 929 / 1500, batch 100%, train loss 1.7307, valid loss 0.2782, cost 0.3 min\n",
      "[[04/23/2020 20:57:41]] epoch 930 / 1500, batch 100%, train loss 0.0822, valid loss 0.2866, cost 0.3 min\n",
      "[[04/23/2020 20:57:55]] epoch 931 / 1500, batch 100%, train loss 0.3132, valid loss 0.2828, cost 0.2 min\n",
      "[[04/23/2020 20:58:15]] epoch 932 / 1500, batch 100%, train loss 0.4183, valid loss 0.2850, cost 0.3 min\n",
      "[[04/23/2020 20:58:35]] epoch 933 / 1500, batch 100%, train loss 0.1126, valid loss 0.2727, cost 0.3 min\n",
      "[[04/23/2020 20:58:54]] epoch 934 / 1500, batch 100%, train loss 0.0317, valid loss 0.2698, cost 0.3 min\n",
      "[[04/23/2020 20:59:09]] epoch 935 / 1500, batch 100%, train loss 0.0594, valid loss 0.2647, cost 0.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 20:59:24]] epoch 936 / 1500, batch 100%, train loss 0.3156, valid loss 0.2689, cost 0.2 min\n",
      "[[04/23/2020 20:59:44]] epoch 937 / 1500, batch 100%, train loss 0.2168, valid loss 0.2653, cost 0.3 min\n",
      "[[04/23/2020 21:00:00]] epoch 938 / 1500, batch 100%, train loss 0.0526, valid loss 0.2702, cost 0.3 min\n",
      "[[04/23/2020 21:00:19]] epoch 939 / 1500, batch 100%, train loss 0.0491, valid loss 0.2691, cost 0.3 min\n",
      "[[04/23/2020 21:00:33]] epoch 940 / 1500, batch 100%, train loss 0.4531, valid loss 0.2701, cost 0.2 min\n",
      "[[04/23/2020 21:00:52]] epoch 941 / 1500, batch 100%, train loss 0.0381, valid loss 0.2790, cost 0.3 min\n",
      "[[04/23/2020 21:01:09]] epoch 942 / 1500, batch 100%, train loss 0.0324, valid loss 0.2753, cost 0.3 min\n",
      "[[04/23/2020 21:01:28]] epoch 943 / 1500, batch 100%, train loss 0.0790, valid loss 0.2825, cost 0.3 min\n",
      "[[04/23/2020 21:01:49]] epoch 944 / 1500, batch 100%, train loss 0.1510, valid loss 0.2810, cost 0.3 min\n",
      "[[04/23/2020 21:02:09]] epoch 945 / 1500, batch 100%, train loss 0.1231, valid loss 0.2833, cost 0.3 min\n",
      "[[04/23/2020 21:02:22]] epoch 946 / 1500, batch 100%, train loss 0.3393, valid loss 0.2858, cost 0.2 min\n",
      "[[04/23/2020 21:02:38]] epoch 947 / 1500, batch 100%, train loss 0.2218, valid loss 0.2817, cost 0.3 min\n",
      "[[04/23/2020 21:02:55]] epoch 948 / 1500, batch 100%, train loss 0.5246, valid loss 0.2782, cost 0.3 min\n",
      "[[04/23/2020 21:03:08]] epoch 949 / 1500, batch 100%, train loss 0.3487, valid loss 0.2720, cost 0.2 min\n",
      "[[04/23/2020 21:03:24]] epoch 950 / 1500, batch 100%, train loss 0.3688, valid loss 0.2680, cost 0.3 min\n",
      "[[04/23/2020 21:03:43]] epoch 951 / 1500, batch 100%, train loss 0.0167, valid loss 0.2621, cost 0.3 min\n",
      "[[04/23/2020 21:04:00]] epoch 952 / 1500, batch 100%, train loss 0.1072, valid loss 0.2625, cost 0.3 min\n",
      "[[04/23/2020 21:04:14]] epoch 953 / 1500, batch 100%, train loss 0.1064, valid loss 0.2610, cost 0.2 min\n",
      "[[04/23/2020 21:04:34]] epoch 954 / 1500, batch 100%, train loss 0.1867, valid loss 0.2689, cost 0.3 min\n",
      "[[04/23/2020 21:04:56]] epoch 955 / 1500, batch 100%, train loss 0.1774, valid loss 0.2613, cost 0.4 min\n",
      "[[04/23/2020 21:05:10]] epoch 956 / 1500, batch 100%, train loss 0.2238, valid loss 0.2604, cost 0.2 min\n",
      "[[04/23/2020 21:05:28]] epoch 957 / 1500, batch 100%, train loss 0.2135, valid loss 0.2641, cost 0.3 min\n",
      "[[04/23/2020 21:05:43]] epoch 958 / 1500, batch 100%, train loss 0.2546, valid loss 0.2657, cost 0.2 min\n",
      "[[04/23/2020 21:06:00]] epoch 959 / 1500, batch 100%, train loss 0.4469, valid loss 0.2641, cost 0.3 min\n",
      "[[04/23/2020 21:06:13]] epoch 960 / 1500, batch 100%, train loss 0.2578, valid loss 0.2606, cost 0.2 min\n",
      "[[04/23/2020 21:06:33]] epoch 961 / 1500, batch 100%, train loss 0.1368, valid loss 0.2628, cost 0.3 min\n",
      "[[04/23/2020 21:06:49]] epoch 962 / 1500, batch 100%, train loss 0.1264, valid loss 0.2583, cost 0.3 min\n",
      "[[04/23/2020 21:07:10]] epoch 963 / 1500, batch 100%, train loss 0.1870, valid loss 0.2631, cost 0.4 min\n",
      "[[04/23/2020 21:07:33]] epoch 964 / 1500, batch 100%, train loss 0.1874, valid loss 0.2616, cost 0.4 min\n",
      "[[04/23/2020 21:07:51]] epoch 965 / 1500, batch 100%, train loss 0.1257, valid loss 0.2638, cost 0.3 min\n",
      "[[04/23/2020 21:08:06]] epoch 966 / 1500, batch 100%, train loss 0.1333, valid loss 0.2711, cost 0.2 min\n",
      "[[04/23/2020 21:08:21]] epoch 967 / 1500, batch 100%, train loss 0.1228, valid loss 0.2685, cost 0.2 min\n",
      "[[04/23/2020 21:08:41]] epoch 968 / 1500, batch 100%, train loss 0.3139, valid loss 0.2663, cost 0.3 min\n",
      "[[04/23/2020 21:09:00]] epoch 969 / 1500, batch 100%, train loss 0.1120, valid loss 0.2692, cost 0.3 min\n",
      "[[04/23/2020 21:09:14]] epoch 970 / 1500, batch 100%, train loss 0.3221, valid loss 0.2656, cost 0.2 min\n",
      "[[04/23/2020 21:09:34]] epoch 971 / 1500, batch 100%, train loss 0.1194, valid loss 0.2662, cost 0.3 min\n",
      "[[04/23/2020 21:09:48]] epoch 972 / 1500, batch 100%, train loss 0.0829, valid loss 0.2685, cost 0.2 min\n",
      "[[04/23/2020 21:10:03]] epoch 973 / 1500, batch 100%, train loss 0.1461, valid loss 0.2609, cost 0.3 min\n",
      "[[04/23/2020 21:10:18]] epoch 974 / 1500, batch 100%, train loss 0.1546, valid loss 0.2686, cost 0.3 min\n",
      "[[04/23/2020 21:10:35]] epoch 975 / 1500, batch 100%, train loss 0.2492, valid loss 0.2623, cost 0.3 min\n",
      "[[04/23/2020 21:10:52]] epoch 976 / 1500, batch 100%, train loss 0.2173, valid loss 0.2623, cost 0.3 min\n",
      "[[04/23/2020 21:11:11]] epoch 977 / 1500, batch 100%, train loss 0.1757, valid loss 0.2663, cost 0.3 min\n",
      "[[04/23/2020 21:11:26]] epoch 978 / 1500, batch 100%, train loss 0.0821, valid loss 0.2671, cost 0.3 min\n",
      "[[04/23/2020 21:11:46]] epoch 979 / 1500, batch 100%, train loss 0.3214, valid loss 0.2627, cost 0.3 min\n",
      "[[04/23/2020 21:12:09]] epoch 980 / 1500, batch 100%, train loss 0.1735, valid loss 0.2619, cost 0.4 min\n",
      "[[04/23/2020 21:12:24]] epoch 981 / 1500, batch 100%, train loss 0.1718, valid loss 0.2657, cost 0.3 min\n",
      "[[04/23/2020 21:12:44]] epoch 982 / 1500, batch 100%, train loss 0.0916, valid loss 0.2635, cost 0.3 min\n",
      "[[04/23/2020 21:13:00]] epoch 983 / 1500, batch 100%, train loss 0.1678, valid loss 0.2642, cost 0.3 min\n",
      "[[04/23/2020 21:13:18]] epoch 984 / 1500, batch 100%, train loss 0.4836, valid loss 0.2747, cost 0.3 min\n",
      "[[04/23/2020 21:13:36]] epoch 985 / 1500, batch 100%, train loss 0.1648, valid loss 0.2757, cost 0.3 min\n",
      "[[04/23/2020 21:13:56]] epoch 986 / 1500, batch 100%, train loss 0.1885, valid loss 0.2789, cost 0.3 min\n",
      "[[04/23/2020 21:14:17]] epoch 987 / 1500, batch 100%, train loss 0.4836, valid loss 0.2722, cost 0.4 min\n",
      "[[04/23/2020 21:14:35]] epoch 988 / 1500, batch 100%, train loss 0.1949, valid loss 0.2691, cost 0.3 min\n",
      "[[04/23/2020 21:14:50]] epoch 989 / 1500, batch 100%, train loss 0.1563, valid loss 0.2674, cost 0.3 min\n",
      "[[04/23/2020 21:15:08]] epoch 990 / 1500, batch 100%, train loss 0.1490, valid loss 0.2681, cost 0.3 min\n",
      "[[04/23/2020 21:15:25]] epoch 991 / 1500, batch 100%, train loss 0.0960, valid loss 0.2669, cost 0.3 min\n",
      "[[04/23/2020 21:15:45]] epoch 992 / 1500, batch 100%, train loss 0.2820, valid loss 0.2674, cost 0.3 min\n",
      "[[04/23/2020 21:16:03]] epoch 993 / 1500, batch 100%, train loss 0.2265, valid loss 0.2699, cost 0.3 min\n",
      "[[04/23/2020 21:16:21]] epoch 994 / 1500, batch 100%, train loss 0.1234, valid loss 0.2662, cost 0.3 min\n",
      "[[04/23/2020 21:16:37]] epoch 995 / 1500, batch 100%, train loss 0.1411, valid loss 0.2702, cost 0.3 min\n",
      "[[04/23/2020 21:16:57]] epoch 996 / 1500, batch 100%, train loss 0.6580, valid loss 0.2674, cost 0.3 min\n",
      "[[04/23/2020 21:17:12]] epoch 997 / 1500, batch 100%, train loss 0.0547, valid loss 0.2629, cost 0.2 min\n",
      "[[04/23/2020 21:17:31]] epoch 998 / 1500, batch 100%, train loss 0.3254, valid loss 0.2618, cost 0.3 min\n",
      "[[04/23/2020 21:17:45]] epoch 999 / 1500, batch 100%, train loss 0.2824, valid loss 0.2624, cost 0.2 min\n",
      "[[04/23/2020 21:18:06]] epoch 1000 / 1500, batch 100%, train loss 0.3154, valid loss 0.2638, cost 0.3 min\n",
      "[[04/23/2020 21:18:23]] epoch 1001 / 1500, batch 100%, train loss 0.1093, valid loss 0.2646, cost 0.3 min\n",
      "[[04/23/2020 21:18:41]] epoch 1002 / 1500, batch 100%, train loss 0.3472, valid loss 0.2665, cost 0.3 min\n",
      "[[04/23/2020 21:18:57]] epoch 1003 / 1500, batch 100%, train loss 0.1125, valid loss 0.2631, cost 0.3 min\n",
      "[[04/23/2020 21:19:12]] epoch 1004 / 1500, batch 100%, train loss 0.1116, valid loss 0.2591, cost 0.2 min\n",
      "[[04/23/2020 21:19:27]] epoch 1005 / 1500, batch 100%, train loss 0.1673, valid loss 0.2692, cost 0.3 min\n",
      "[[04/23/2020 21:19:43]] epoch 1006 / 1500, batch 100%, train loss 0.4033, valid loss 0.2757, cost 0.3 min\n",
      "[[04/23/2020 21:20:02]] epoch 1007 / 1500, batch 100%, train loss 0.1604, valid loss 0.2857, cost 0.3 min\n",
      "[[04/23/2020 21:20:18]] epoch 1008 / 1500, batch 100%, train loss 0.1237, valid loss 0.2906, cost 0.3 min\n",
      "[[04/23/2020 21:20:35]] epoch 1009 / 1500, batch 100%, train loss 0.1348, valid loss 0.2907, cost 0.3 min\n",
      "[[04/23/2020 21:20:51]] epoch 1010 / 1500, batch 100%, train loss 0.0714, valid loss 0.2944, cost 0.3 min\n",
      "[[04/23/2020 21:21:04]] epoch 1011 / 1500, batch 100%, train loss 0.0919, valid loss 0.2855, cost 0.2 min\n",
      "[[04/23/2020 21:21:21]] epoch 1012 / 1500, batch 100%, train loss 0.0731, valid loss 0.2831, cost 0.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 21:21:38]] epoch 1013 / 1500, batch 100%, train loss 0.1445, valid loss 0.2827, cost 0.3 min\n",
      "[[04/23/2020 21:21:55]] epoch 1014 / 1500, batch 100%, train loss 0.0558, valid loss 0.2780, cost 0.3 min\n",
      "[[04/23/2020 21:22:16]] epoch 1015 / 1500, batch 100%, train loss 0.1884, valid loss 0.2667, cost 0.3 min\n",
      "[[04/23/2020 21:22:32]] epoch 1016 / 1500, batch 100%, train loss 0.0752, valid loss 0.2739, cost 0.3 min\n",
      "[[04/23/2020 21:22:46]] epoch 1017 / 1500, batch 100%, train loss 0.2905, valid loss 0.2694, cost 0.2 min\n",
      "[[04/23/2020 21:23:04]] epoch 1018 / 1500, batch 100%, train loss 0.0606, valid loss 0.2573, cost 0.3 min\n",
      "[[04/23/2020 21:23:22]] epoch 1019 / 1500, batch 100%, train loss 0.1953, valid loss 0.2630, cost 0.3 min\n",
      "[[04/23/2020 21:23:37]] epoch 1020 / 1500, batch 100%, train loss 0.0423, valid loss 0.2602, cost 0.3 min\n",
      "[[04/23/2020 21:23:53]] epoch 1021 / 1500, batch 100%, train loss 0.1438, valid loss 0.2616, cost 0.3 min\n",
      "[[04/23/2020 21:24:10]] epoch 1022 / 1500, batch 100%, train loss 0.4126, valid loss 0.2637, cost 0.3 min\n",
      "[[04/23/2020 21:24:29]] epoch 1023 / 1500, batch 100%, train loss 0.1180, valid loss 0.2661, cost 0.3 min\n",
      "[[04/23/2020 21:24:45]] epoch 1024 / 1500, batch 100%, train loss 0.1274, valid loss 0.2751, cost 0.3 min\n",
      "[[04/23/2020 21:25:04]] epoch 1025 / 1500, batch 100%, train loss 0.0900, valid loss 0.2722, cost 0.3 min\n",
      "[[04/23/2020 21:25:25]] epoch 1026 / 1500, batch 100%, train loss 0.2679, valid loss 0.2796, cost 0.4 min\n",
      "[[04/23/2020 21:25:40]] epoch 1027 / 1500, batch 100%, train loss 0.1541, valid loss 0.2848, cost 0.2 min\n",
      "[[04/23/2020 21:25:55]] epoch 1028 / 1500, batch 100%, train loss 0.2392, valid loss 0.2780, cost 0.2 min\n",
      "[[04/23/2020 21:26:14]] epoch 1029 / 1500, batch 100%, train loss 0.1827, valid loss 0.2745, cost 0.3 min\n",
      "[[04/23/2020 21:26:30]] epoch 1030 / 1500, batch 100%, train loss 0.0669, valid loss 0.2659, cost 0.3 min\n",
      "[[04/23/2020 21:26:50]] epoch 1031 / 1500, batch 100%, train loss 0.3528, valid loss 0.2623, cost 0.3 min\n",
      "[[04/23/2020 21:27:03]] epoch 1032 / 1500, batch 100%, train loss 0.3573, valid loss 0.2559, cost 0.2 min\n",
      "[[04/23/2020 21:27:19]] epoch 1033 / 1500, batch 100%, train loss 0.2242, valid loss 0.2638, cost 0.3 min\n",
      "[[04/23/2020 21:27:33]] epoch 1034 / 1500, batch 100%, train loss 0.1484, valid loss 0.2584, cost 0.2 min\n",
      "[[04/23/2020 21:27:53]] epoch 1035 / 1500, batch 100%, train loss 0.1927, valid loss 0.2619, cost 0.3 min\n",
      "[[04/23/2020 21:28:06]] epoch 1036 / 1500, batch 100%, train loss 0.4734, valid loss 0.2784, cost 0.2 min\n",
      "[[04/23/2020 21:28:23]] epoch 1037 / 1500, batch 100%, train loss 0.1103, valid loss 0.2882, cost 0.3 min\n",
      "[[04/23/2020 21:28:39]] epoch 1038 / 1500, batch 100%, train loss 0.1387, valid loss 0.2865, cost 0.3 min\n",
      "[[04/23/2020 21:28:59]] epoch 1039 / 1500, batch 100%, train loss 0.1254, valid loss 0.2849, cost 0.3 min\n",
      "[[04/23/2020 21:29:18]] epoch 1040 / 1500, batch 100%, train loss 0.1346, valid loss 0.2830, cost 0.3 min\n",
      "[[04/23/2020 21:29:40]] epoch 1041 / 1500, batch 100%, train loss 0.4016, valid loss 0.2737, cost 0.4 min\n",
      "[[04/23/2020 21:29:58]] epoch 1042 / 1500, batch 100%, train loss 0.1056, valid loss 0.2685, cost 0.3 min\n",
      "[[04/23/2020 21:30:18]] epoch 1043 / 1500, batch 100%, train loss 0.5516, valid loss 0.2672, cost 0.3 min\n",
      "[[04/23/2020 21:30:37]] epoch 1044 / 1500, batch 100%, train loss 0.1125, valid loss 0.2664, cost 0.3 min\n",
      "[[04/23/2020 21:30:57]] epoch 1045 / 1500, batch 100%, train loss 0.1435, valid loss 0.2685, cost 0.3 min\n",
      "[[04/23/2020 21:31:14]] epoch 1046 / 1500, batch 100%, train loss 0.1674, valid loss 0.2734, cost 0.3 min\n",
      "[[04/23/2020 21:31:31]] epoch 1047 / 1500, batch 100%, train loss 0.0898, valid loss 0.2854, cost 0.3 min\n",
      "[[04/23/2020 21:31:48]] epoch 1048 / 1500, batch 100%, train loss 0.2290, valid loss 0.2913, cost 0.3 min\n",
      "[[04/23/2020 21:32:06]] epoch 1049 / 1500, batch 100%, train loss 0.2224, valid loss 0.2823, cost 0.3 min\n",
      "[[04/23/2020 21:32:22]] epoch 1050 / 1500, batch 100%, train loss 0.1308, valid loss 0.2721, cost 0.3 min\n",
      "[[04/23/2020 21:32:43]] epoch 1051 / 1500, batch 100%, train loss 0.0688, valid loss 0.2671, cost 0.4 min\n",
      "[[04/23/2020 21:33:02]] epoch 1052 / 1500, batch 100%, train loss 0.0592, valid loss 0.2656, cost 0.3 min\n",
      "[[04/23/2020 21:33:23]] epoch 1053 / 1500, batch 100%, train loss 0.1340, valid loss 0.2634, cost 0.4 min\n",
      "[[04/23/2020 21:33:45]] epoch 1054 / 1500, batch 100%, train loss 0.0360, valid loss 0.2593, cost 0.4 min\n",
      "[[04/23/2020 21:34:06]] epoch 1055 / 1500, batch 100%, train loss 0.1829, valid loss 0.2607, cost 0.3 min\n",
      "[[04/23/2020 21:34:22]] epoch 1056 / 1500, batch 100%, train loss 0.0881, valid loss 0.2663, cost 0.3 min\n",
      "[[04/23/2020 21:34:37]] epoch 1057 / 1500, batch 100%, train loss 0.1116, valid loss 0.2653, cost 0.3 min\n",
      "[[04/23/2020 21:34:55]] epoch 1058 / 1500, batch 100%, train loss 0.0809, valid loss 0.2733, cost 0.3 min\n",
      "[[04/23/2020 21:35:09]] epoch 1059 / 1500, batch 100%, train loss 0.0487, valid loss 0.2710, cost 0.2 min\n",
      "[[04/23/2020 21:35:25]] epoch 1060 / 1500, batch 100%, train loss 0.0540, valid loss 0.2698, cost 0.3 min\n",
      "[[04/23/2020 21:35:42]] epoch 1061 / 1500, batch 100%, train loss 0.1238, valid loss 0.2768, cost 0.3 min\n",
      "[[04/23/2020 21:35:57]] epoch 1062 / 1500, batch 100%, train loss 0.1159, valid loss 0.2735, cost 0.2 min\n",
      "[[04/23/2020 21:36:14]] epoch 1063 / 1500, batch 100%, train loss 0.0762, valid loss 0.2687, cost 0.3 min\n",
      "[[04/23/2020 21:36:32]] epoch 1064 / 1500, batch 100%, train loss 0.3384, valid loss 0.2637, cost 0.3 min\n",
      "[[04/23/2020 21:36:49]] epoch 1065 / 1500, batch 100%, train loss 0.2626, valid loss 0.2749, cost 0.3 min\n",
      "[[04/23/2020 21:37:07]] epoch 1066 / 1500, batch 100%, train loss 0.0866, valid loss 0.2649, cost 0.3 min\n",
      "[[04/23/2020 21:37:24]] epoch 1067 / 1500, batch 100%, train loss 0.0602, valid loss 0.2660, cost 0.3 min\n",
      "[[04/23/2020 21:37:39]] epoch 1068 / 1500, batch 100%, train loss 0.0468, valid loss 0.2610, cost 0.2 min\n",
      "[[04/23/2020 21:37:58]] epoch 1069 / 1500, batch 100%, train loss 0.1233, valid loss 0.2670, cost 0.3 min\n",
      "[[04/23/2020 21:38:12]] epoch 1070 / 1500, batch 100%, train loss 0.8200, valid loss 0.2637, cost 0.2 min\n",
      "[[04/23/2020 21:38:35]] epoch 1071 / 1500, batch 100%, train loss 0.1854, valid loss 0.2645, cost 0.4 min\n",
      "[[04/23/2020 21:38:52]] epoch 1072 / 1500, batch 100%, train loss 0.0878, valid loss 0.2608, cost 0.3 min\n",
      "[[04/23/2020 21:39:10]] epoch 1073 / 1500, batch 100%, train loss 0.0968, valid loss 0.2599, cost 0.3 min\n",
      "[[04/23/2020 21:39:25]] epoch 1074 / 1500, batch 100%, train loss 0.2700, valid loss 0.2598, cost 0.3 min\n",
      "[[04/23/2020 21:39:46]] epoch 1075 / 1500, batch 100%, train loss 0.1223, valid loss 0.2653, cost 0.3 min\n",
      "[[04/23/2020 21:40:02]] epoch 1076 / 1500, batch 100%, train loss 0.1219, valid loss 0.2627, cost 0.3 min\n",
      "[[04/23/2020 21:40:17]] epoch 1077 / 1500, batch 100%, train loss 0.3900, valid loss 0.2608, cost 0.3 min\n",
      "[[04/23/2020 21:40:33]] epoch 1078 / 1500, batch 100%, train loss 0.0551, valid loss 0.2652, cost 0.3 min\n",
      "[[04/23/2020 21:40:53]] epoch 1079 / 1500, batch 100%, train loss 0.1978, valid loss 0.2734, cost 0.3 min\n",
      "[[04/23/2020 21:41:08]] epoch 1080 / 1500, batch 100%, train loss 0.3904, valid loss 0.2732, cost 0.3 min\n",
      "[[04/23/2020 21:41:24]] epoch 1081 / 1500, batch 100%, train loss 0.3449, valid loss 0.2725, cost 0.3 min\n",
      "[[04/23/2020 21:41:41]] epoch 1082 / 1500, batch 100%, train loss 0.1802, valid loss 0.2753, cost 0.3 min\n",
      "[[04/23/2020 21:42:00]] epoch 1083 / 1500, batch 100%, train loss 0.2353, valid loss 0.2736, cost 0.3 min\n",
      "[[04/23/2020 21:42:17]] epoch 1084 / 1500, batch 100%, train loss 0.2600, valid loss 0.2726, cost 0.3 min\n",
      "[[04/23/2020 21:42:35]] epoch 1085 / 1500, batch 100%, train loss 0.1158, valid loss 0.2774, cost 0.3 min\n",
      "[[04/23/2020 21:42:51]] epoch 1086 / 1500, batch 100%, train loss 0.0418, valid loss 0.2738, cost 0.3 min\n",
      "[[04/23/2020 21:43:10]] epoch 1087 / 1500, batch 100%, train loss 0.2598, valid loss 0.2796, cost 0.3 min\n",
      "[[04/23/2020 21:43:29]] epoch 1088 / 1500, batch 100%, train loss 0.2260, valid loss 0.2725, cost 0.3 min\n",
      "[[04/23/2020 21:43:47]] epoch 1089 / 1500, batch 100%, train loss 0.2991, valid loss 0.2771, cost 0.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/23/2020 21:44:02]] epoch 1090 / 1500, batch 100%, train loss 0.0458, valid loss 0.2745, cost 0.2 min\n",
      "[[04/23/2020 21:44:22]] epoch 1091 / 1500, batch 100%, train loss 0.2495, valid loss 0.2683, cost 0.3 min\n",
      "[[04/23/2020 21:44:42]] epoch 1092 / 1500, batch 100%, train loss 0.1088, valid loss 0.2675, cost 0.3 min\n",
      "[[04/23/2020 21:44:57]] epoch 1093 / 1500, batch 100%, train loss 0.2080, valid loss 0.2664, cost 0.3 min\n",
      "[[04/23/2020 21:45:16]] epoch 1094 / 1500, batch 100%, train loss 0.1093, valid loss 0.2658, cost 0.3 min\n",
      "[[04/23/2020 21:45:31]] epoch 1095 / 1500, batch 100%, train loss 0.1449, valid loss 0.2691, cost 0.2 min\n",
      "[[04/23/2020 21:45:49]] epoch 1096 / 1500, batch 100%, train loss 0.1907, valid loss 0.2626, cost 0.3 min\n",
      "[[04/23/2020 21:46:10]] epoch 1097 / 1500, batch 100%, train loss 0.4063, valid loss 0.2605, cost 0.4 min\n",
      "[[04/23/2020 21:46:24]] epoch 1098 / 1500, batch 100%, train loss 0.1397, valid loss 0.2650, cost 0.2 min\n",
      "[[04/23/2020 21:46:42]] epoch 1099 / 1500, batch 100%, train loss 0.2333, valid loss 0.2692, cost 0.3 min\n",
      "[[04/23/2020 21:47:00]] epoch 1100 / 1500, batch 100%, train loss 0.0984, valid loss 0.2653, cost 0.3 min\n",
      "[[04/23/2020 21:47:18]] epoch 1101 / 1500, batch 100%, train loss 0.0754, valid loss 0.2629, cost 0.3 min\n",
      "[[04/23/2020 21:47:35]] epoch 1102 / 1500, batch 100%, train loss 0.3121, valid loss 0.2640, cost 0.3 min\n",
      "[[04/23/2020 21:47:58]] epoch 1103 / 1500, batch 100%, train loss 0.2009, valid loss 0.2611, cost 0.4 min\n",
      "[[04/23/2020 21:48:16]] epoch 1104 / 1500, batch 100%, train loss 0.3806, valid loss 0.2628, cost 0.3 min\n",
      "[[04/23/2020 21:48:34]] epoch 1105 / 1500, batch 100%, train loss 0.1455, valid loss 0.2641, cost 0.3 min\n",
      "[[04/23/2020 21:48:49]] epoch 1106 / 1500, batch 100%, train loss 0.2056, valid loss 0.2606, cost 0.3 min\n",
      "[[04/23/2020 21:49:06]] epoch 1107 / 1500, batch 100%, train loss 0.0555, valid loss 0.2649, cost 0.3 min\n",
      "[[04/23/2020 21:49:22]] epoch 1108 / 1500, batch 100%, train loss 0.0937, valid loss 0.2598, cost 0.3 min\n",
      "[[04/23/2020 21:49:40]] epoch 1109 / 1500, batch 100%, train loss 0.4207, valid loss 0.2667, cost 0.3 min\n",
      "[[04/23/2020 21:49:52]] epoch 1110 / 1500, batch 100%, train loss 0.1249, valid loss 0.2663, cost 0.2 min\n",
      "[[04/23/2020 21:50:09]] epoch 1111 / 1500, batch 100%, train loss 0.1255, valid loss 0.2633, cost 0.3 min\n",
      "[[04/23/2020 21:50:21]] epoch 1112 / 1500, batch 100%, train loss 0.0853, valid loss 0.2664, cost 0.2 min\n",
      "[[04/23/2020 21:50:37]] epoch 1113 / 1500, batch 100%, train loss 0.1649, valid loss 0.2620, cost 0.3 min\n",
      "[[04/23/2020 21:50:55]] epoch 1114 / 1500, batch 100%, train loss 0.1602, valid loss 0.2667, cost 0.3 min\n",
      "[[04/23/2020 21:51:19]] epoch 1115 / 1500, batch 100%, train loss 0.3721, valid loss 0.2638, cost 0.4 min\n",
      "[[04/23/2020 21:51:39]] epoch 1116 / 1500, batch 100%, train loss 0.0408, valid loss 0.2583, cost 0.3 min\n",
      "[[04/23/2020 21:52:02]] epoch 1117 / 1500, batch 100%, train loss 0.2388, valid loss 0.2626, cost 0.4 min\n",
      "[[04/23/2020 21:52:23]] epoch 1118 / 1500, batch 100%, train loss 0.1755, valid loss 0.2641, cost 0.4 min\n",
      "[[04/23/2020 21:52:43]] epoch 1119 / 1500, batch 100%, train loss 0.2248, valid loss 0.2658, cost 0.3 min\n",
      "[[04/23/2020 21:52:59]] epoch 1120 / 1500, batch 100%, train loss 0.1003, valid loss 0.2580, cost 0.3 min\n",
      "[[04/23/2020 21:53:15]] epoch 1121 / 1500, batch 100%, train loss 0.3281, valid loss 0.2649, cost 0.3 min\n",
      "[[04/23/2020 21:53:30]] epoch 1122 / 1500, batch 100%, train loss 0.1577, valid loss 0.2603, cost 0.2 min\n",
      "[[04/23/2020 21:53:45]] epoch 1123 / 1500, batch 100%, train loss 0.0666, valid loss 0.2670, cost 0.3 min\n",
      "[[04/24/2020 09:12:54]] epoch 1124 / 1500, batch 100%, train loss 0.1056, valid loss 0.2618, cost 679.1 min\n",
      "[[04/24/2020 09:13:14]] epoch 1125 / 1500, batch 100%, train loss 0.1677, valid loss 0.2683, cost 0.3 min\n",
      "[[04/24/2020 09:13:30]] epoch 1126 / 1500, batch 100%, train loss 0.1260, valid loss 0.2601, cost 0.3 min\n",
      "[[04/24/2020 09:13:47]] epoch 1127 / 1500, batch 100%, train loss 0.2158, valid loss 0.2607, cost 0.3 min\n",
      "[[04/24/2020 09:14:07]] epoch 1128 / 1500, batch 100%, train loss 0.1508, valid loss 0.2559, cost 0.3 min\n",
      "[[04/24/2020 09:14:24]] epoch 1129 / 1500, batch 100%, train loss 0.1883, valid loss 0.2603, cost 0.3 min\n",
      "[[04/24/2020 09:14:38]] epoch 1130 / 1500, batch 100%, train loss 0.2444, valid loss 0.2620, cost 0.2 min\n",
      "[[04/24/2020 09:14:55]] epoch 1131 / 1500, batch 100%, train loss 0.1433, valid loss 0.2628, cost 0.3 min\n",
      "[[04/24/2020 09:15:11]] epoch 1132 / 1500, batch 100%, train loss 0.2379, valid loss 0.2682, cost 0.3 min\n",
      "[[04/24/2020 09:15:30]] epoch 1133 / 1500, batch 100%, train loss 0.4154, valid loss 0.2653, cost 0.3 min\n",
      "[[04/24/2020 09:15:44]] epoch 1134 / 1500, batch 100%, train loss 0.5810, valid loss 0.2776, cost 0.2 min\n",
      "[[04/24/2020 09:15:59]] epoch 1135 / 1500, batch 100%, train loss 0.1183, valid loss 0.2838, cost 0.2 min\n",
      "[[04/24/2020 09:16:15]] epoch 1136 / 1500, batch 100%, train loss 0.0546, valid loss 0.2929, cost 0.3 min\n",
      "[[04/24/2020 09:16:35]] epoch 1137 / 1500, batch 100%, train loss 0.2628, valid loss 0.2887, cost 0.3 min\n",
      "[[04/24/2020 09:16:52]] epoch 1138 / 1500, batch 100%, train loss 0.0425, valid loss 0.2861, cost 0.3 min\n",
      "[[04/24/2020 09:17:06]] epoch 1139 / 1500, batch 100%, train loss 0.3655, valid loss 0.2812, cost 0.2 min\n",
      "[[04/24/2020 09:17:23]] epoch 1140 / 1500, batch 100%, train loss 0.1692, valid loss 0.2790, cost 0.3 min\n",
      "[[04/24/2020 09:17:44]] epoch 1141 / 1500, batch 100%, train loss 0.1099, valid loss 0.2706, cost 0.4 min\n",
      "[[04/24/2020 09:18:03]] epoch 1142 / 1500, batch 100%, train loss 0.2021, valid loss 0.2719, cost 0.3 min\n",
      "[[04/24/2020 09:18:21]] epoch 1143 / 1500, batch 100%, train loss 0.3733, valid loss 0.2650, cost 0.3 min\n",
      "[[04/24/2020 09:18:39]] epoch 1144 / 1500, batch 100%, train loss 0.4180, valid loss 0.2658, cost 0.3 min\n",
      "[[04/24/2020 09:18:59]] epoch 1145 / 1500, batch 100%, train loss 0.2503, valid loss 0.2694, cost 0.3 min\n",
      "[[04/24/2020 09:19:19]] epoch 1146 / 1500, batch 100%, train loss 0.1744, valid loss 0.2680, cost 0.3 min\n",
      "[[04/24/2020 09:19:40]] epoch 1147 / 1500, batch 100%, train loss 0.1159, valid loss 0.2663, cost 0.4 min\n",
      "[[04/24/2020 09:19:59]] epoch 1148 / 1500, batch 100%, train loss 0.0792, valid loss 0.2614, cost 0.3 min\n",
      "[[04/24/2020 09:20:15]] epoch 1149 / 1500, batch 100%, train loss 0.0873, valid loss 0.2621, cost 0.3 min\n",
      "[[04/24/2020 09:20:31]] epoch 1150 / 1500, batch 100%, train loss 0.1623, valid loss 0.2664, cost 0.3 min\n",
      "[[04/24/2020 09:20:50]] epoch 1151 / 1500, batch 100%, train loss 0.0818, valid loss 0.2717, cost 0.3 min\n",
      "[[04/24/2020 09:21:06]] epoch 1152 / 1500, batch 100%, train loss 0.0735, valid loss 0.2702, cost 0.3 min\n",
      "[[04/24/2020 09:21:27]] epoch 1153 / 1500, batch 100%, train loss 0.3201, valid loss 0.2668, cost 0.4 min\n",
      "[[04/24/2020 09:21:47]] epoch 1154 / 1500, batch 100%, train loss 0.2624, valid loss 0.2658, cost 0.3 min\n",
      "[[04/24/2020 09:22:05]] epoch 1155 / 1500, batch 100%, train loss 0.0760, valid loss 0.2664, cost 0.3 min\n",
      "[[04/24/2020 09:22:24]] epoch 1156 / 1500, batch 100%, train loss 0.1565, valid loss 0.2658, cost 0.3 min\n",
      "[[04/24/2020 09:22:39]] epoch 1157 / 1500, batch 100%, train loss 0.1541, valid loss 0.2751, cost 0.3 min\n",
      "[[04/24/2020 09:22:56]] epoch 1158 / 1500, batch 100%, train loss 0.0947, valid loss 0.2731, cost 0.3 min\n",
      "[[04/24/2020 09:23:16]] epoch 1159 / 1500, batch 100%, train loss 0.1238, valid loss 0.2788, cost 0.3 min\n",
      "[[04/24/2020 09:23:29]] epoch 1160 / 1500, batch 100%, train loss 0.3577, valid loss 0.2664, cost 0.2 min\n",
      "[[04/24/2020 09:23:47]] epoch 1161 / 1500, batch 100%, train loss 0.2086, valid loss 0.2790, cost 0.3 min\n",
      "[[04/24/2020 09:24:06]] epoch 1162 / 1500, batch 100%, train loss 0.2311, valid loss 0.2886, cost 0.3 min\n",
      "[[04/24/2020 09:24:23]] epoch 1163 / 1500, batch 100%, train loss 0.1327, valid loss 0.2922, cost 0.3 min\n",
      "[[04/24/2020 09:24:41]] epoch 1164 / 1500, batch 100%, train loss 0.1053, valid loss 0.2989, cost 0.3 min\n",
      "[[04/24/2020 09:24:59]] epoch 1165 / 1500, batch 100%, train loss 0.1235, valid loss 0.3011, cost 0.3 min\n",
      "[[04/24/2020 09:25:16]] epoch 1166 / 1500, batch 100%, train loss 0.0845, valid loss 0.2977, cost 0.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[04/24/2020 09:25:33]] epoch 1167 / 1500, batch 100%, train loss 0.5044, valid loss 0.2877, cost 0.3 min\n",
      "[[04/24/2020 09:25:48]] epoch 1168 / 1500, batch 100%, train loss 0.0924, valid loss 0.2801, cost 0.2 min\n",
      "[[04/24/2020 09:26:07]] epoch 1169 / 1500, batch 100%, train loss 0.0777, valid loss 0.2802, cost 0.3 min\n",
      "[[04/24/2020 09:26:20]] epoch 1170 / 1500, batch 100%, train loss 0.1355, valid loss 0.2725, cost 0.2 min\n",
      "[[04/24/2020 09:26:36]] epoch 1171 / 1500, batch 100%, train loss 0.3390, valid loss 0.2699, cost 0.3 min\n",
      "[[04/24/2020 09:26:59]] epoch 1172 / 1500, batch 100%, train loss 0.2015, valid loss 0.2651, cost 0.4 min\n",
      "[[04/24/2020 09:27:18]] epoch 1173 / 1500, batch 100%, train loss 0.0533, valid loss 0.2692, cost 0.3 min\n"
     ]
    }
   ],
   "source": [
    "model = Wave2WaveV1(enc_num=9+8, dec_num=6+8, n_layers=8, n_blocks=3, \n",
    "                enc_cat=[(63, 4)], dec_cat=[(63, 4)], dropout=0.1, debug=False, hidden_size=512)\n",
    "opt = Adam(model.parameters(), 0.002)\n",
    "loss_fn = MSELoss()\n",
    "model.cuda()\n",
    "lr_scheduler = ReduceCosineAnnealingLR(opt, 64)\n",
    "learner = Learner(model, opt, loss_fn, './power_env', verbose=5000, lr_scheduler=lr_scheduler)\n",
    "learner.fit(1500, train_frame, valid_frame, patient=64, start_save=1, early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xy = torch.as_tensor(xy[:, :, test_idx]).cuda()\n",
    "test_xf = torch.as_tensor(np.concatenate([xy_num_features[:, :, test_idx], x_num_features[:, :, test_idx]], axis=1)).cuda()\n",
    "test_yf = torch.as_tensor(xy_num_features[:, :, test_idx]).cuda()\n",
    "\n",
    "def plot(x_true, y_true, y_pred):\n",
    "    enc_ticks = np.arange(x_true.shape[1])\n",
    "    dec_ticks = np.arange(y_pred.shape[1]) + x_true.shape[1]\n",
    "    for idx, name in enumerate(power.index):\n",
    "        plt.figure(figsize=(12, 3))\n",
    "        plt.plot(enc_ticks, x_true[idx])\n",
    "        plt.plot(dec_ticks, y_pred[idx], label='pred')\n",
    "        plt.plot(dec_ticks, y_true[idx], label='true')\n",
    "        plt.title(name)\n",
    "        plt.legend()\n",
    "\n",
    "def wmape(y_hat, y):\n",
    "    scores = []\n",
    "    for day in range(int(y.shape[0] / 24)):\n",
    "        scores.append(np.abs(y[day*24: (day+1)*24] - y_hat[day*24: (day+1)*24]).sum() / np.sum(y[day*24: (day+1)*24]))\n",
    "    return scores\n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    scores = {}\n",
    "    for idx, name in enumerate(power.index):\n",
    "        scores[name] = wmape(y_pred[idx], y_true[idx])\n",
    "    return pd.DataFrame(scores)\n",
    "\n",
    "def wmape_dataframe(y_hat, y):\n",
    "    scores = []\n",
    "    for day in range(int(y.shape[0] / 96)):\n",
    "        scores.append(np.abs(y[day*96: (day+1)*96] - y_hat[day*96: (day+1)*96]).sum() / np.sum(y[day*96: (day+1)*96]))\n",
    "    return scores\n",
    "\n",
    "def metric_dataframe(y_true, y_pred):\n",
    "    scores = {}\n",
    "    for idx, name in enumerate(power.index):\n",
    "        scores[name] = wmape_dataframe(y_pred.iloc[idx], y_true.iloc[idx])\n",
    "    return pd.DataFrame(scores)\n",
    "\n",
    "def predict(learner, xy, x_feats, y_feats, epoch):\n",
    "    learner.load(epoch)\n",
    "    learner.model.eval()\n",
    "    learner.model.cuda()\n",
    "    preds = []\n",
    "    days = int(xy.shape[2] / 24 - ENC_LEN / 24 - DEC_LEN/24 + 1)\n",
    "    for day in range(days):\n",
    "        step = day * 24\n",
    "#         enc_start = day\n",
    "#         enc_end = (step+ENC_LEN) / 24\n",
    "#         dec_start = enc_end\n",
    "#         dec_end = (step+ENC_LEN+DEC_LEN) / 24\n",
    "#         print(f\"start {enc_start}, end {int(dec_end)}\" )\n",
    "        step_pred = model(\n",
    "            xy[:, :, step: step+ENC_LEN], \n",
    "            enc_num=x_feats[:, :, step: step+ENC_LEN],\n",
    "            dec_num=y_feats[:, :, step+ENC_LEN: step+ENC_LEN+DEC_LEN], dec_len=DEC_LEN).cpu().detach().numpy()\n",
    "        if step == 0:\n",
    "            preds.append(step_pred)\n",
    "        else:\n",
    "            preds.append(step_pred[:, :, -24:])\n",
    "    preds = np.concatenate(preds, axis=2)\n",
    "    preds = np.expm1(preds.squeeze() * series_std + series_mu)\n",
    "    \n",
    "    x_true = np.expm1(xy[:, :, :ENC_LEN].cpu().numpy().squeeze() * series_std + series_mu)\n",
    "    y_true = np.expm1(xy[:, :, ENC_LEN:].cpu().numpy().squeeze() * series_std + series_mu)\n",
    "    \n",
    "    return x_true, y_true, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = pd.read_csv(\"./data/20200315_20200415.csv\").drop(['Unnamed: 0', 'model_name'], axis=1)\n",
    "norm_data = norm_data[norm_data.contributor_id.isin(power.index)].reset_index(drop=True)\n",
    "norm_data = norm_data.set_index(\"contributor_id\").loc[power.index].reset_index()\n",
    "norm_data['data_time'] = pd.to_datetime(norm_data.data_time)\n",
    "norm_data = norm_data.set_index(\"data_time\").groupby(\"contributor_id\").resample('1H')[['forecast_pwr', 'value']].sum().reset_index()\n",
    "norm_true = norm_data.pivot(index='contributor_id', columns='data_time', values='value').iloc[:, 48:]\n",
    "norm_pred = norm_data.pivot(index='contributor_id', columns='data_time', values='forecast_pwr').iloc[:, 48:]\n",
    "\n",
    "\n",
    "x_true, y_true, y_pred  = predict(learner, test_xy, test_xf, test_yf, 1014)\n",
    "scores = pd.DataFrame([metric(y_true, y_pred).mean().rename(\"wave\"), \n",
    "                       metric(norm_true.values, norm_pred.values).mean().rename(\"v1\")]).T.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_true, y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
